{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#slise-sparse-linear-subset-explanations","title":"SLISE - Sparse Linear Subset Explanations","text":"<p>Python implementation of the SLISE algorithm. The SLISE algorithm can be used for both robust regression and to explain outcomes from black box models. For more details see the conference paper, the robust regression paper, or the local explanation paper. Alternatively for a more informal overview see the presentation, or the poster. Finally, for learning to use the python package there are several examples and the documentation.</p> <p>Bj\u00f6rklund A., Henelius A., Oikarinen E., Kallonen K., Puolam\u00e4ki K. (2019) Sparse Robust Regression for Explaining Classifiers. Discovery Science (DS 2019). Lecture Notes in Computer Science, vol 11828, Springer. https://doi.org/10.1007/978-3-030-33778-0_27  </p> <p>Bj\u00f6rklund A., Henelius A., Oikarinen E., Kallonen K., Puolam\u00e4ki K. (2022). Robust regression via error tolerance. Data Mining and Knowledge Discovery. https://doi.org/10.1007/s10618-022-00819-2  </p> <p>Bj\u00f6rklund A., Henelius A., Oikarinen E., Kallonen K., Puolam\u00e4ki K. (2023) Explaining any black box model using real data. Frontiers in Computer Science 5:1143904. https://doi.org/10.3389/fcomp.2023.1143904  </p>"},{"location":"#the-idea","title":"The idea","text":"<p>In robust regression we fit regression models that can handle data that contains outliers (see the example below for why outliers are problematic for normal regression). SLISE accomplishes this by fitting a model such that the largest possible subset of the data items have an error less than a given value. All items with an error larger than that are considered potential outliers and do not affect the resulting model.</p> <p>SLISE can also be used to provide local model-agnostic explanations for outcomes from black box models. To do this we replace the ground truth response vector with the predictions from the complex model. Furthermore, we force the model to fit a selected item (making the explanation local). This gives us a local approximation of the complex model with a simpler linear model (this is similar to, e.g., LIME and SHAP). In contrast to other methods SLISE creates explanations using real data (not some discretised and randomly sampled data) so we can be sure that all inputs are valid (i.e. in the correct data manifold, and follows the constraints used to generate the data, e.g., the laws of physics).</p>"},{"location":"#installation","title":"Installation","text":"<p>To install this package just run:</p> <pre><code>pip install slise\n</code></pre> <p>Or install the latest version directly from GitHub:</p> <pre><code>pip install git+https://github.com/edahelsinki/pyslise\n</code></pre> <p>Alternatively you can download the repo and run <code>python -m build</code> to build a wheel, or <code>pip install .</code> to install it locally.</p>"},{"location":"#numba","title":"Numba","text":"<p>SLISE uses Numba to speed up the calculations. You might want to install the optional libraries to get the most out of Numba:</p> <pre><code>pip install \"slise[tbb]\"\n</code></pre>"},{"location":"#other-implementations","title":"Other implementations","text":"<p>The (original) R implementation can be found here.</p>"},{"location":"#examples","title":"Examples","text":"<p>Here are two quick examples of SLISE in action. For more detailed examples, with descriptions on how to create and interpret them, see the examples directory.</p> <p> SLISE is a robust regression algorithm, which means that it is able to handle outliers. This is in contrast to, e.g., ordinary least-squares regression, which gives skewed results when outliers are present.</p> <p> </p> <p> SLISE can also be used to explain outcomes from black box models by locally approximating the complex models with a simpler linear model.</p>"},{"location":"#dependencies","title":"Dependencies","text":"<p>This implementation requires Python 3 and the following packages:</p> <ul> <li>matplotlib</li> <li>numba</li> <li>numpy</li> <li>PyLBFGS</li> <li>scipy</li> </ul>"},{"location":"docs/slise.data/","title":"slise.data","text":""},{"location":"docs/slise.data/#slise.data","title":"<code>slise.data</code>","text":"<p>This script contains functions for modifying data, mainly normalisation and PCA.</p>"},{"location":"docs/slise.data/#slise.data.DataScaling","title":"<code>DataScaling</code>","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Container class for scaling information</p> Source code in <code>slise/data.py</code> <pre><code>class DataScaling(NamedTuple):\n    \"\"\"\n    Container class for scaling information\n    \"\"\"\n\n    x_center: np.ndarray\n    x_scale: np.ndarray\n    y_center: float\n    y_scale: float\n    columns: np.ndarray\n\n    def scale_x(self, x: np.ndarray, remove_columns: bool = True) -&gt; np.ndarray:\n        \"\"\"Scale a x matrix / vector using the stored scaling information.\n        See [slise.data.scale_same][].\n\n        Args:\n            x (np.ndarray): New x matrix / vector.\n            remove_columns (bool, optional): Remove columns according to the stored information. Defaults to True.\n\n        Returns:\n            np.ndarray: Scaled matrix / vector.\n        \"\"\"\n        return scale_same(x, self.x_center, self.x_scale, self.columns, remove_columns)\n\n    def scale_y(self, y: Union[float, np.ndarray]) -&gt; Union[float, np.ndarray]:\n        \"\"\"Scale a y vector / scalar using the stored scaling information.\n        See [slise.data.scale_same][].\n\n        Args:\n            y (np.ndarray): New y vector / scalar.\n\n        Returns:\n            np.ndarray: Scaled y vector / scalar.\n        \"\"\"\n        return scale_same(y, self.y_center, self.y_scale)\n\n    def unscale_model(self, model: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Unscale a linear model.\n        See [slise.data.unscale_model][].\n\n        Args:\n            model (np.ndarray): Linear model operating on scaled data.\n\n        Returns:\n            np.ndarray: Linear model operating on unscaled data.\n        \"\"\"\n        return unscale_model(\n            model,\n            self.x_center,\n            self.x_scale,\n            self.y_center,\n            self.y_scale,\n            self.columns,\n        )\n</code></pre>"},{"location":"docs/slise.data/#slise.data.DataScaling.scale_x","title":"<code>scale_x(x, remove_columns=True)</code>","text":"<p>Scale a x matrix / vector using the stored scaling information. See slise.data.scale_same.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>New x matrix / vector.</p> required <code>remove_columns</code> <code>bool</code> <p>Remove columns according to the stored information. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Scaled matrix / vector.</p> Source code in <code>slise/data.py</code> <pre><code>def scale_x(self, x: np.ndarray, remove_columns: bool = True) -&gt; np.ndarray:\n    \"\"\"Scale a x matrix / vector using the stored scaling information.\n    See [slise.data.scale_same][].\n\n    Args:\n        x (np.ndarray): New x matrix / vector.\n        remove_columns (bool, optional): Remove columns according to the stored information. Defaults to True.\n\n    Returns:\n        np.ndarray: Scaled matrix / vector.\n    \"\"\"\n    return scale_same(x, self.x_center, self.x_scale, self.columns, remove_columns)\n</code></pre>"},{"location":"docs/slise.data/#slise.data.DataScaling.scale_y","title":"<code>scale_y(y)</code>","text":"<p>Scale a y vector / scalar using the stored scaling information. See slise.data.scale_same.</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>ndarray</code> <p>New y vector / scalar.</p> required <p>Returns:</p> Type Description <code>Union[float, ndarray]</code> <p>np.ndarray: Scaled y vector / scalar.</p> Source code in <code>slise/data.py</code> <pre><code>def scale_y(self, y: Union[float, np.ndarray]) -&gt; Union[float, np.ndarray]:\n    \"\"\"Scale a y vector / scalar using the stored scaling information.\n    See [slise.data.scale_same][].\n\n    Args:\n        y (np.ndarray): New y vector / scalar.\n\n    Returns:\n        np.ndarray: Scaled y vector / scalar.\n    \"\"\"\n    return scale_same(y, self.y_center, self.y_scale)\n</code></pre>"},{"location":"docs/slise.data/#slise.data.DataScaling.unscale_model","title":"<code>unscale_model(model)</code>","text":"<p>Unscale a linear model. See slise.data.unscale_model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>ndarray</code> <p>Linear model operating on scaled data.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Linear model operating on unscaled data.</p> Source code in <code>slise/data.py</code> <pre><code>def unscale_model(self, model: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Unscale a linear model.\n    See [slise.data.unscale_model][].\n\n    Args:\n        model (np.ndarray): Linear model operating on scaled data.\n\n    Returns:\n        np.ndarray: Linear model operating on unscaled data.\n    \"\"\"\n    return unscale_model(\n        model,\n        self.x_center,\n        self.x_scale,\n        self.y_center,\n        self.y_scale,\n        self.columns,\n    )\n</code></pre>"},{"location":"docs/slise.data/#slise.data.add_intercept_column","title":"<code>add_intercept_column(X)</code>","text":"<p>Add a constant column of ones to the matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Matrix or vector.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Matrix / vector where the first column / value is one.</p> Source code in <code>slise/data.py</code> <pre><code>def add_intercept_column(X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Add a constant column of ones to the matrix.\n\n    Args:\n        X (np.ndarray): Matrix or vector.\n\n    Returns:\n        np.ndarray: Matrix / vector where the first column / value is one.\n    \"\"\"\n    if len(X.shape) == 1:\n        return np.concatenate(([1.0], X))\n    return np.concatenate((np.ones((X.shape[0], 1)), X), 1)\n</code></pre>"},{"location":"docs/slise.data/#slise.data.remove_intercept_column","title":"<code>remove_intercept_column(X)</code>","text":"<p>Remove the first column. Used to revert slise.data.add_intercept_column.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Matrix or vector.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Matrix / vector without the first column / value.</p> Source code in <code>slise/data.py</code> <pre><code>def remove_intercept_column(X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Remove the first column.\n    Used to revert [slise.data.add_intercept_column][].\n\n    Args:\n        X (np.ndarray): Matrix or vector.\n\n    Returns:\n        np.ndarray: Matrix / vector without the first column / value.\n    \"\"\"\n    if len(X.shape) == 1:\n        return X[1:]\n    return X[:, 1:]\n</code></pre>"},{"location":"docs/slise.data/#slise.data.remove_constant_columns","title":"<code>remove_constant_columns(X, epsilon=None)</code>","text":"<p>Remove columns that are constant from a matrix. Used to revert slise.data.add_constant_columns.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>epsilon</code> <code>Optional[float]</code> <p>Treshold for constant (std &lt; epsilon). Defaults to machine epsilon.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: A tuple of the reduced matrix and a mask showing which columns where retained.</p> Source code in <code>slise/data.py</code> <pre><code>def remove_constant_columns(\n    X: np.ndarray, epsilon: Optional[float] = None\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Remove columns that are constant from a matrix.\n    Used to revert [slise.data.add_constant_columns][].\n\n    Args:\n        X (np.ndarray): Data matrix.\n        epsilon (Optional[float], optional): Treshold for constant (std &lt; epsilon). Defaults to machine epsilon.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: A tuple of the reduced matrix and a mask showing which columns where retained.\n    \"\"\"\n    if epsilon is None:\n        epsilon = np.finfo(X.dtype).eps\n    std = np.std(X, 0)\n    mask = std &gt; epsilon\n    return X[:, mask], mask\n</code></pre>"},{"location":"docs/slise.data/#slise.data.add_constant_columns","title":"<code>add_constant_columns(X, mask, intercept=False)</code>","text":"<p>Add (back) contant columns to a matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>mask</code> <code>Optional[ndarray]</code> <p>A boolean array showing which columns are already in the matrix.</p> required <code>intercept</code> <code>bool</code> <p>Does X has an intercept (added to it after constant columns where removed). Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A matrix with new columns filled with zeros.</p> Source code in <code>slise/data.py</code> <pre><code>def add_constant_columns(\n    X: np.ndarray, mask: Optional[np.ndarray], intercept: bool = False\n) -&gt; np.ndarray:\n    \"\"\"Add (back) contant columns to a matrix.\n\n    Args:\n        X (np.ndarray): Data matrix.\n        mask (Optional[np.ndarray]): A boolean array showing which columns are already in the matrix.\n        intercept (bool, optional): Does X has an intercept (added to it after constant columns where removed). Defaults to False.\n\n    Returns:\n        np.ndarray: A matrix with new columns filled with zeros.\n    \"\"\"\n    if mask is None:\n        return X\n    if intercept:\n        mask = np.concatenate(([True], mask))\n    if len(X.shape) &lt; 2:\n        X2 = np.zeros(len(mask), X.dtype)\n        X2[mask] = X\n        return X2\n    else:\n        X2 = np.zeros((X.shape[0], len(mask)), X.dtype)\n        X2[:, mask] = X\n        return X2\n</code></pre>"},{"location":"docs/slise.data/#slise.data.normalise_robust","title":"<code>normalise_robust(x, epsilon=None)</code>","text":"<p>A robust version of normalisation that uses median and mad (median absolute deviation).     Any zeros in the scale are replaced by ones to avoid division by zero.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Vector or tensor to normalise.</p> required <code>epsilon</code> <code>Optional[float]</code> <p>Threshold for the scale being zero. Defaults to machine epsilon.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, Union[float, ndarray], Union[float, ndarray]]</code> <p>Tuple[np.ndarray, Union[float, np.ndarray], Union[float, np.ndarray]]: Tuple of normalised x, center and scale.</p> Source code in <code>slise/data.py</code> <pre><code>def normalise_robust(\n    x: np.ndarray, epsilon: Optional[float] = None\n) -&gt; Tuple[np.ndarray, Union[float, np.ndarray], Union[float, np.ndarray]]:\n    \"\"\"A robust version of normalisation that uses median and mad (median absolute deviation).\n        Any zeros in the scale are replaced by ones to avoid division by zero.\n\n    Args:\n        x (np.ndarray): Vector or tensor to normalise.\n        epsilon (Optional[float], optional): Threshold for the scale being zero. Defaults to machine epsilon.\n\n    Returns:\n        Tuple[np.ndarray, Union[float, np.ndarray], Union[float, np.ndarray]]: Tuple of normalised x, center and scale.\n    \"\"\"\n    if epsilon is None:\n        epsilon = np.finfo(x.dtype).eps\n    if len(x.shape) &lt; 2:\n        center = np.median(x)\n        x = x - center\n        scale = np.median(np.abs(x))\n        if scale &lt;= epsilon:\n            scale = 1.0\n        return x / scale, center, scale\n    else:\n        center = np.median(x, 0)\n        x = x - center[None, :]\n        scale = np.median(np.abs(x), 0)\n        scale[scale &lt;= epsilon] = 1.0\n        return x / scale[None, :], center, scale\n</code></pre>"},{"location":"docs/slise.data/#slise.data.scale_same","title":"<code>scale_same(x, center, scale, constant_colums=None, remove_columns=True)</code>","text":"<p>Scale a matrix or vector the same way as another.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Matrix or vector to scale.</p> required <code>center</code> <code>Union[float, ndarray]</code> <p>The center used for the previous scaling.</p> required <code>scale</code> <code>Union[float, ndarray]</code> <p>The scale used for the previous scaling.</p> required <code>constant_colums</code> <code>Optional[ndarray]</code> <p>Boolean mask of constant columns. Defaults to None.</p> <code>None</code> <code>remove_columns</code> <code>bool</code> <p>Should constant columns be removed. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scaled matrix/vector.</p> Source code in <code>slise/data.py</code> <pre><code>def scale_same(\n    x: Union[np.ndarray, float],\n    center: Union[float, np.ndarray],\n    scale: Union[float, np.ndarray],\n    constant_colums: Optional[np.ndarray] = None,\n    remove_columns: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Scale a matrix or vector the same way as another.\n\n    Args:\n        x (np.ndarray): Matrix or vector to scale.\n        center (Union[float, np.ndarray]): The center used for the previous scaling.\n        scale (Union[float, np.ndarray]): The scale used for the previous scaling.\n        constant_colums (Optional[np.ndarray], optional): Boolean mask of constant columns. Defaults to None.\n        remove_columns (bool, optional): Should constant columns be removed. Defaults to True.\n\n    Returns:\n        np.ndarray: The scaled matrix/vector.\n    \"\"\"\n    if isinstance(x, float) or len(x.shape) &lt; 2:\n        if constant_colums is not None:\n            if not remove_columns:\n                y = np.zeros_like(x)\n                y[constant_colums] = (x[constant_colums] - center) / scale\n                return y\n            x = x[constant_colums]\n        return (x - center) / scale\n    else:\n        if constant_colums is not None:\n            if not remove_columns:\n                y = np.zeros_like(x)\n                y[:, constant_colums] = (\n                    x[:, constant_colums] - center[None, :]\n                ) / scale[None, :]\n                return y\n            x = x[:, constant_colums]\n        return (x - center[None, :]) / scale[None, :]\n</code></pre>"},{"location":"docs/slise.data/#slise.data.unscale_model","title":"<code>unscale_model(model, x_center, x_scale, y_center=0.0, y_scale=1.0, columns=None)</code>","text":"<p>Scale a linear model such that it matches unnormalised data.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>ndarray</code> <p>The model for normalised data.</p> required <code>x_center</code> <code>ndarray</code> <p>The center used for normalising X.</p> required <code>x_scale</code> <code>ndarray</code> <p>The scale used for normalising X.</p> required <code>y_center</code> <code>float</code> <p>The scale used for normalising y. Defaults to 0.0.</p> <code>0.0</code> <code>y_scale</code> <code>float</code> <p>The center used for normalising y. Defaults to 1.0.</p> <code>1.0</code> <code>columns</code> <code>Optional[ndarray]</code> <p>Mask of removed columns (see remove_constant_columns). Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The unscaled model.</p> Source code in <code>slise/data.py</code> <pre><code>def unscale_model(\n    model: np.ndarray,\n    x_center: np.ndarray,\n    x_scale: np.ndarray,\n    y_center: float = 0.0,\n    y_scale: float = 1.0,\n    columns: Optional[np.ndarray] = None,\n) -&gt; np.ndarray:\n    \"\"\"Scale a linear model such that it matches unnormalised data.\n\n    Args:\n        model (np.ndarray): The model for normalised data.\n        x_center (np.ndarray): The center used for normalising X.\n        x_scale (np.ndarray): The scale used for normalising X.\n        y_center (float, optional): The scale used for normalising y. Defaults to 0.0.\n        y_scale (float, optional): The center used for normalising y. Defaults to 1.0.\n        columns (Optional[np.ndarray], optional): Mask of removed columns (see remove_constant_columns). Defaults to None.\n\n    Returns:\n        np.ndarray: The unscaled model.\n    \"\"\"\n    if len(model) == len(x_center):\n        model = np.concatenate((np.zeros(1, x_center.dtype), model))\n    else:\n        model = model.copy()\n    model[0] = (model[0] - np.sum(model[1:] * x_center / x_scale)) * y_scale + y_center\n    model[1:] = model[1:] / x_scale * y_scale\n    if columns is not None:\n        return add_constant_columns(model, columns, True)\n    else:\n        return model\n</code></pre>"},{"location":"docs/slise.data/#slise.data.pca_simple","title":"<code>pca_simple(x, dimensions=10, tolerance=1e-10)</code>","text":"<p>Fit and use PCA for dimensionality reduction.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Matrix to reduce.</p> required <code>dimensions</code> <code>int</code> <p>The number of dimensions to return. Defaults to 10.</p> <code>10</code> <code>tolerance</code> <code>float</code> <p>Threshold for variance being zero. Defaults to 1e-10.</p> <code>1e-10</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: Tuple of the reduced matrix and PCA rotation matrix.</p> Source code in <code>slise/data.py</code> <pre><code>def pca_simple(\n    x: np.ndarray, dimensions: int = 10, tolerance: float = 1e-10\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Fit and use PCA for dimensionality reduction.\n\n    Args:\n        x (np.ndarray): Matrix to reduce.\n        dimensions (int, optional): The number of dimensions to return. Defaults to 10.\n        tolerance (float, optional): Threshold for variance being zero. Defaults to 1e-10.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: Tuple of the reduced matrix and PCA rotation matrix.\n    \"\"\"\n    if len(x.shape) == 1:\n        return x, 1.0\n    dimensions = min(dimensions, *x.shape)\n    u, s, v = np.linalg.svd(x, False, True, False)\n    dimensions = max(1, np.sum(s[: min(dimensions, len(s))] &gt; s[0] * tolerance))\n    return u[:, :dimensions].dot(np.diag(s[:dimensions])), v[:dimensions, :]\n</code></pre>"},{"location":"docs/slise.data/#slise.data.pca_rotate","title":"<code>pca_rotate(x, v)</code>","text":"<p>Use a trained PCA for dimensionality reduction. See slise.data.pca_simple for how to obtain a rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Matrix to reduce.</p> required <code>v</code> <code>ndarray</code> <p>PCA rotation matrix.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The reduced matrix.</p> Source code in <code>slise/data.py</code> <pre><code>def pca_rotate(x: np.ndarray, v: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Use a trained PCA for dimensionality reduction.\n    See [slise.data.pca_simple][] for how to obtain a rotation matrix.\n\n    Args:\n        x (np.ndarray): Matrix to reduce.\n        v (np.ndarray): PCA rotation matrix.\n\n    Returns:\n        np.ndarray: The reduced matrix.\n    \"\"\"\n    return x @ v.T\n</code></pre>"},{"location":"docs/slise.data/#slise.data.pca_invert","title":"<code>pca_invert(x, v)</code>","text":"<p>Revert a PCA dimensionality reduction. See slise.data.pca_simple for how to obtain a rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Matrix to expand.</p> required <code>v</code> <code>ndarray</code> <p>PCA rotation matrix.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The expanded matrix.</p> Source code in <code>slise/data.py</code> <pre><code>def pca_invert(x: np.ndarray, v: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Revert a PCA dimensionality reduction.\n    See [slise.data.pca_simple][] for how to obtain a rotation matrix.\n\n    Args:\n        x (np.ndarray): Matrix to expand.\n        v (np.ndarray): PCA rotation matrix.\n\n    Returns:\n        np.ndarray: The expanded matrix.\n    \"\"\"\n    return x @ v\n</code></pre>"},{"location":"docs/slise.data/#slise.data.pca_rotate_model","title":"<code>pca_rotate_model(model, v)</code>","text":"<p>Transform a linear model to work in PCA reduced space. See slise.data.pca_simple for how to obtain a rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>ndarray</code> <p>Linear model coefficients.</p> required <code>v</code> <code>ndarray</code> <p>PCA rotation matrix.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The transformed linear model.</p> Source code in <code>slise/data.py</code> <pre><code>def pca_rotate_model(model: np.ndarray, v: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Transform a linear model to work in PCA reduced space.\n    See [slise.data.pca_simple][] for how to obtain a rotation matrix.\n\n    Args:\n        model (np.ndarray): Linear model coefficients.\n        v (np.ndarray): PCA rotation matrix.\n\n    Returns:\n        np.ndarray: The transformed linear model.\n    \"\"\"\n    if len(model) &gt; v.shape[1]:\n        return np.concatenate((model[:1], v @ model[1:]))\n    return v @ model\n</code></pre>"},{"location":"docs/slise.data/#slise.data.pca_invert_model","title":"<code>pca_invert_model(model, v)</code>","text":"<p>Transform a linear model from PCA space to \"normal\" space. See slise.data.pca_simple for how to obtain a rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>ndarray</code> <p>Linear model coefficients (in PCA space).</p> required <code>v</code> <code>ndarray</code> <p>PCA rotation matrix.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The transformed linear model.</p> Source code in <code>slise/data.py</code> <pre><code>def pca_invert_model(model: np.ndarray, v: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Transform a linear model from PCA space to \"normal\" space.\n    See [slise.data.pca_simple][] for how to obtain a rotation matrix.\n\n    Args:\n        model (np.ndarray): Linear model coefficients (in PCA space).\n        v (np.ndarray): PCA rotation matrix.\n\n    Returns:\n        np.ndarray: The transformed linear model.\n    \"\"\"\n    if len(model) &gt; v.shape[0]:\n        return np.concatenate((model[:1], v.T @ model[1:]))\n    return v.T @ model\n</code></pre>"},{"location":"docs/slise.initialisation/","title":"slise.initialisation","text":""},{"location":"docs/slise.initialisation/#slise.initialisation","title":"<code>slise.initialisation</code>","text":"<p>This script contains functions for initialising alpha and beta in SLISE.</p>"},{"location":"docs/slise.initialisation/#slise.initialisation.fast_lstsq","title":"<code>fast_lstsq(x, y, weight=None, max_iterations=300)</code>","text":"<p>A fast version of least squares that falls back to optimisation if the input size is too large.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Data matrix.</p> required <code>y</code> <code>ndarray</code> <p>Response vector.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>The number of iterations to use in case of optimisation. Defaults to 300.</p> <code>300</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: vector of coefficients</p> Source code in <code>slise/initialisation.py</code> <pre><code>def fast_lstsq(\n    x: np.ndarray,\n    y: np.ndarray,\n    weight: Optional[np.ndarray] = None,\n    max_iterations: int = 300,\n) -&gt; np.ndarray:\n    \"\"\"A fast version of least squares that falls back to optimisation if the input size is too large.\n\n    Args:\n        x (np.ndarray): Data matrix.\n        y (np.ndarray): Response vector.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        max_iterations (int, optional): The number of iterations to use in case of optimisation. Defaults to 300.\n\n    Returns:\n        np.ndarray: vector of coefficients\n    \"\"\"\n    if weight is None or x.shape[1] &lt;= max_iterations * 20:\n        return np.linalg.lstsq(x, y, rcond=None)[0]\n    else:\n        return regularised_regression(x, y, 0.0, 0.0, weight, max_iterations)\n</code></pre>"},{"location":"docs/slise.initialisation/#slise.initialisation.initialise_lasso","title":"<code>initialise_lasso(X, Y, epsilon=0.0, weight=None, max_iterations=300, **kwargs)</code>","text":"<p>Initialise <code>alpha</code> and <code>beta</code> to be equivalent to LASSO.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>The error tolerance. Defaults to 0.</p> <code>0.0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>The number of iterations to use in case of optimisation. Defaults to 300.</p> <code>300</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: <code>(alpha, beta)</code>.</p> Source code in <code>slise/initialisation.py</code> <pre><code>def initialise_lasso(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float = 0.0,\n    weight: Optional[np.ndarray] = None,\n    max_iterations: int = 300,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Initialise `alpha` and `beta` to be equivalent to LASSO.\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float, optional): The error tolerance. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        max_iterations (int, optional): The number of iterations to use in case of optimisation. Defaults to 300.\n\n    Returns:\n        Tuple[np.ndarray, float]: `(alpha, beta)`.\n    \"\"\"\n    return fast_lstsq(X, Y, weight, max_iterations), 0.0\n</code></pre>"},{"location":"docs/slise.initialisation/#slise.initialisation.initialise_ols","title":"<code>initialise_ols(X, Y, epsilon, weight=None, beta_max=20.0, max_approx=1.15, max_iterations=300, beta_max_init=2.5, min_beta_step=1e-08, **kwargs)</code>","text":"<p>Initialise <code>alpha</code> to OLS and <code>beta</code> to slise.optimisation.next_beta.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>The error tolerance. Defaults to 0.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20.0</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>max_iterations</code> <code>int</code> <p>The number of iterations to use in case of optimisation. Defaults to 300.</p> <code>300</code> <code>beta_max_init</code> <code>float</code> <p>Maximum beta. Defaults to 2.5.</p> <code>2.5</code> <code>min_beta_step</code> <code>float</code> <p>Minimum beta. Defaults to 1e-8.</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: <code>(alpha, beta)</code>.</p> Source code in <code>slise/initialisation.py</code> <pre><code>def initialise_ols(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 20.0,\n    max_approx: float = 1.15,\n    max_iterations: int = 300,\n    beta_max_init: float = 2.5,\n    min_beta_step: float = 1e-8,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Initialise `alpha` to OLS and `beta` to [slise.optimisation.next_beta][].\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float, optional): The error tolerance. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        max_iterations (int, optional): The number of iterations to use in case of optimisation. Defaults to 300.\n        beta_max_init (float, optional): Maximum beta. Defaults to 2.5.\n        min_beta_step (float, optional): Minimum beta. Defaults to 1e-8.\n\n    Returns:\n        Tuple[np.ndarray, float]: `(alpha, beta)`.\n    \"\"\"\n    alpha = fast_lstsq(X, Y, weight, max_iterations)\n    epsilon = epsilon**2\n    beta_max = min(beta_max, beta_max_init) / epsilon\n    r2 = (Y - X @ alpha) ** 2\n    beta = next_beta(r2, epsilon, 0, weight, beta_max, log(max_approx), min_beta_step)\n    return alpha, beta\n</code></pre>"},{"location":"docs/slise.initialisation/#slise.initialisation.initialise_zeros","title":"<code>initialise_zeros(X, Y, epsilon, weight=None, beta_max=20.0, max_approx=1.15, beta_max_init=2.5, min_beta_step=1e-08, **kwargs)</code>","text":"<p>Initialise <code>alpha</code> to 0 and <code>beta</code> to slise.optimisation.next_beta.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>The error tolerance. Defaults to 0.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20.0</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>beta_max_init</code> <code>float</code> <p>Maximum beta. Defaults to 2.5.</p> <code>2.5</code> <code>min_beta_step</code> <code>float</code> <p>Minimum beta. Defaults to 1e-8.</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: <code>(alpha, beta)</code>.</p> Source code in <code>slise/initialisation.py</code> <pre><code>def initialise_zeros(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 20.0,\n    max_approx: float = 1.15,\n    beta_max_init: float = 2.5,\n    min_beta_step: float = 1e-8,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Initialise `alpha` to 0 and `beta` to [slise.optimisation.next_beta][].\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float, optional): The error tolerance. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        beta_max_init (float, optional): Maximum beta. Defaults to 2.5.\n        min_beta_step (float, optional): Minimum beta. Defaults to 1e-8.\n\n    Returns:\n        Tuple[np.ndarray, float]: `(alpha, beta)`.\n    \"\"\"\n    epsilon = epsilon**2\n    beta_max = min(beta_max, beta_max_init) / epsilon\n    beta = next_beta(Y**2, epsilon, 0, weight, beta_max, log(max_approx), min_beta_step)\n    return np.zeros(X.shape[1]), beta\n</code></pre>"},{"location":"docs/slise.initialisation/#slise.initialisation.initialise_fixed","title":"<code>initialise_fixed(init, X, Y, epsilon, weight=None, beta_max=20.0, max_approx=1.15, beta_max_init=2.5, min_beta_step=1e-08)</code>","text":"<p>Initialise <code>alpha</code> and <code>beta</code> to the given values (or slise.optimisation.next_beta if <code>beta</code> is not given).</p> <p>Parameters:</p> Name Type Description Default <code>init</code> <code>Union[ndarray, Tuple[ndarray, float]]</code> <p>The fixed <code>alpha</code>, and optional <code>beta</code>.</p> required <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>The error tolerance. Defaults to 0.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20.0</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>beta_max_init</code> <code>float</code> <p>Maximum beta. Defaults to 2.5.</p> <code>2.5</code> <code>min_beta_step</code> <code>float</code> <p>Minimum beta. Defaults to 1e-8.</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: <code>(alpha, beta)</code>.</p> Source code in <code>slise/initialisation.py</code> <pre><code>def initialise_fixed(\n    init: Union[np.ndarray, Tuple[np.ndarray, float]],\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 20.0,\n    max_approx: float = 1.15,\n    beta_max_init: float = 2.5,\n    min_beta_step: float = 1e-8,\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Initialise `alpha` and `beta` to the given values (or [slise.optimisation.next_beta][] if `beta` is not given).\n\n    Args:\n        init (Union[np.ndarray, Tuple[np.ndarray, float]]): The fixed `alpha`, and optional `beta`.\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float, optional): The error tolerance. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        beta_max_init (float, optional): Maximum beta. Defaults to 2.5.\n        min_beta_step (float, optional): Minimum beta. Defaults to 1e-8.\n\n    Returns:\n        Tuple[np.ndarray, float]: `(alpha, beta)`.\n    \"\"\"\n    if isinstance(init, tuple):\n        alpha, beta = init\n    else:\n        epsilon = epsilon**2\n        beta_max = min(beta_max, beta_max_init) / epsilon\n        alpha = init\n        r2 = (X @ alpha - Y) ** 2\n        beta = next_beta(r2, epsilon, 0, weight, beta_max, log(max_approx))\n    return alpha, beta\n</code></pre>"},{"location":"docs/slise.initialisation/#slise.initialisation.initialise_candidates","title":"<code>initialise_candidates(X, Y, epsilon, weight=None, beta_max=20.0, max_approx=1.15, pca_treshold=10, num_init=None, max_iterations=300, beta_max_init=2.5, min_beta_step=1e-08, **kwargs)</code>","text":"<p>Generate a number (num_init) of candidates, using PCA to shrink the random subsets.     Then select the best one to be <code>alpha</code> and <code>beta</code> to be the corresponding slise.optimisation.next_beta.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>The error tolerance. Defaults to 0.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20.0</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>pca_treshold</code> <code>int</code> <p>Treshold number of dimension to use PCA. Defaults to 10.</p> <code>10</code> <code>num_init</code> <code>int</code> <p>Number of candidates to generate. Defaults to 500.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>The number of iterations to use in case of optimisation. Defaults to 300.</p> <code>300</code> <code>beta_max_init</code> <code>float</code> <p>Maximum beta. Defaults to 2.5.</p> <code>2.5</code> <code>min_beta_step</code> <code>float</code> <p>Minimum beta. Defaults to 1e-8.</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: <code>(alpha, beta)</code>.</p> Source code in <code>slise/initialisation.py</code> <pre><code>def initialise_candidates(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 20.0,\n    max_approx: float = 1.15,\n    pca_treshold: int = 10,\n    num_init: Optional[int] = None,\n    max_iterations: int = 300,\n    beta_max_init: float = 2.5,\n    min_beta_step: float = 1e-8,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Generate a number (num_init) of candidates, using PCA to shrink the random subsets.\n        Then select the best one to be `alpha` and `beta` to be the corresponding [slise.optimisation.next_beta][].\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float, optional): The error tolerance. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        pca_treshold (int, optional): Treshold number of dimension to use PCA. Defaults to 10.\n        num_init (int, optional): Number of candidates to generate. Defaults to 500.\n        max_iterations (int, optional): The number of iterations to use in case of optimisation. Defaults to 300.\n        beta_max_init (float, optional): Maximum beta. Defaults to 2.5.\n        min_beta_step (float, optional): Minimum beta. Defaults to 1e-8.\n\n    Returns:\n        Tuple[np.ndarray, float]: `(alpha, beta)`.\n    \"\"\"\n    if num_init is None:\n        num_init = min(500, 3 * 4 ** X.shape[1])\n    # Prepare parameters\n    epsilon = epsilon**2\n    beta_max = min(beta_max, beta_max_init) / epsilon\n    max_approx = log(max_approx)\n    if weight is not None:\n        weight = weight / np.sum(weight)\n    # Initial model (zeros)\n    alpha = np.zeros(X.shape[1])\n    residuals = Y**2\n    beta = next_beta(residuals, epsilon, 0, weight, beta_max, max_approx, min_beta_step)\n    loss = loss_residuals(alpha, residuals, epsilon, beta, 0.0, 0.0, weight)\n    # Find the candidate with the best loss for the next_beta\n    for i in range(num_init):\n        try:\n            model = __create_candidate(X, Y, weight, pca_treshold, max_iterations)\n            r2 = (Y - X @ model) ** 2\n            loss2 = loss_residuals(model, r2, epsilon, beta, 0.0, 0.0, weight)\n            if loss2 &lt; loss:\n                alpha = model\n                beta = next_beta(\n                    r2, epsilon, 0.0, weight, beta_max, max_approx, min_beta_step\n                )\n                loss = loss_residuals(model, r2, epsilon, beta, 0.0, 0.0, weight)\n        except np.linalg.LinAlgError:\n            pass\n    return alpha, beta\n</code></pre>"},{"location":"docs/slise.initialisation/#slise.initialisation.initialise_candidates2","title":"<code>initialise_candidates2(X, Y, epsilon, weight=None, beta_max=20.0, max_approx=1.15, num_init=None, max_iterations=300, beta_max_init=2.5, min_beta_step=1e-08, **kwargs)</code>","text":"<p>Generate a number (num_init) of candidates, using LASSO to shrink the random subsets.     Then select the best one to be <code>alpha</code> and <code>beta</code> to be the corresponding slise.optimisation.next_beta.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>The error tolerance. Defaults to 0.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20.0</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>num_init</code> <code>int</code> <p>Number of candidates to generate. Defaults to 500.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>The number of iterations to use in case of optimisation. Defaults to 300.</p> <code>300</code> <code>beta_max_init</code> <code>float</code> <p>Maximum beta. Defaults to 2.5.</p> <code>2.5</code> <code>min_beta_step</code> <code>float</code> <p>Minimum beta. Defaults to 1e-8.</p> <code>1e-08</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: <code>(alpha, beta)</code>.</p> Source code in <code>slise/initialisation.py</code> <pre><code>def initialise_candidates2(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 20.0,\n    max_approx: float = 1.15,\n    num_init: Optional[int] = None,\n    max_iterations: int = 300,\n    beta_max_init: float = 2.5,\n    min_beta_step: float = 1e-8,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Generate a number (num_init) of candidates, using LASSO to shrink the random subsets.\n        Then select the best one to be `alpha` and `beta` to be the corresponding [slise.optimisation.next_beta][].\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float, optional): The error tolerance. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        num_init (int, optional): Number of candidates to generate. Defaults to 500.\n        max_iterations (int, optional): The number of iterations to use in case of optimisation. Defaults to 300.\n        beta_max_init (float, optional): Maximum beta. Defaults to 2.5.\n        min_beta_step (float, optional): Minimum beta. Defaults to 1e-8.\n\n    Returns:\n        Tuple[np.ndarray, float]: `(alpha, beta)`.\n    \"\"\"\n    if num_init is None:\n        num_init = min(500, 3 * 4 ** X.shape[1])\n    # Prepare parameters\n    epsilon = epsilon**2\n    beta_max = min(beta_max, beta_max_init) / epsilon\n    max_approx = log(max_approx)\n    if weight is not None:\n        weight = weight / np.sum(weight)\n    # Initial model (zeros)\n    alpha = np.zeros(X.shape[1])\n    r2 = Y**2\n    beta = next_beta(r2, epsilon, 0.0, weight, beta_max, max_approx, min_beta_step)\n    loss = loss_residuals(alpha, r2, epsilon, beta, 0.0, 0.0, weight)\n    # Find the candidate with the best loss for the next_beta\n    for i in range(num_init):\n        try:\n            model = __create_candidate2(X, Y, weight, max_iterations)\n            r2 = (Y - X @ model) ** 2\n            loss2 = loss_residuals(model, r2, epsilon, beta, 0.0, 0.0, weight)\n            if loss2 &lt; loss:\n                alpha = model\n                beta = next_beta(\n                    r2, epsilon, 0.0, weight, beta_max, max_approx, min_beta_step\n                )\n                loss = loss_residuals(model, r2, epsilon, beta, 0.0, 0.0, weight)\n        except np.linalg.LinAlgError:\n            pass\n    return alpha, beta\n</code></pre>"},{"location":"docs/slise/","title":"slise","text":""},{"location":"docs/slise/#slise","title":"<code>slise</code>","text":""},{"location":"docs/slise/#slise--slise-sparse-linear-subset-explanations","title":"SLISE - Sparse Linear Subset Explanations","text":"<p>The SLISE algorithm can be used for both robust regression and to explain outcomes from black box models. See slise.slise.regression and slise.slise.explain for referense.</p> <p>In robust regression we fit regression models that can handle data that contains outliers. SLISE accomplishes this by fitting a model such that the largest possible subset of the data items have an error less than a given value. All items with an error larger than that are considered potential outliers and do not affect the resulting model.</p> <p>SLISE can also be used to provide local model-agnostic explanations for outcomes from black box models. To do this we replace the ground truth response vector with the predictions from the complex model. Furthermore, we force the model to fit a selected item (making the explanation local). This gives us a local approximation of the complex model with a simpler linear model. In contrast to other methods SLISE creates explanations using real data (not some discretised and randomly sampled data) so we can be sure that all inputs are valid (i.e. in the correct data manifold, and follows the constraints used to generate the data, e.g., the laws of physics).</p> <p>More in-depth details about the algorithm can be found in the papers:</p> <p>Bj\u00f6rklund A., Henelius A., Oikarinen E., Kallonen K., Puolam\u00e4ki K. Sparse Robust Regression for Explaining Classifiers. Discovery Science (DS 2019). Lecture Notes in Computer Science, vol 11828, Springer. https://doi.org/10.1007/978-3-030-33778-0_27</p> <p>Bj\u00f6rklund A., Henelius A., Oikarinen E., Kallonen K., Puolam\u00e4ki K. Robust regression via error tolerance. Data Mining and Knowledge Discovery (2022). https://doi.org/10.1007/s10618-022-00819-2</p> <p>Bj\u00f6rklund A., Henelius A., Oikarinen E., Kallonen K., Puolam\u00e4ki K. Explaining any black box model using real data. Frontiers in Computer Science 5:1143904 (2023). https://doi.org/10.3389/fcomp.2023.1143904</p>"},{"location":"docs/slise.optimisation/","title":"slise.optimisation","text":""},{"location":"docs/slise.optimisation/#slise.optimisation","title":"<code>slise.optimisation</code>","text":"<p>This script contains the loss functions and optimisation functions for SLISE.</p>"},{"location":"docs/slise.optimisation/#slise.optimisation.loss_smooth","title":"<code>loss_smooth(alpha, X, Y, epsilon, beta=100, lambda1=0, lambda2=0, weight=None)</code>","text":"<p>Smoothed version of the SLISE loss (slise.optimisation.loss_sharp).</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Linear model coefficients.</p> required <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>beta</code> <code>float</code> <p>Sigmoid steepness. Defaults to 100.</p> <code>100</code> <code>lambda1</code> <code>float</code> <p>LASSO/L1 regularisation coefficient. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>Ridge/L2 regularisation coefficient. Defaults to 0.</p> <code>0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Loss value.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def loss_smooth(\n    alpha: np.ndarray,\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    beta: float = 100,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    weight: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Smoothed version of the SLISE loss ([slise.optimisation.loss_sharp][]).\n\n    Args:\n        alpha (np.ndarray): Linear model coefficients.\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float): Error tolerance.\n        beta (float, optional): Sigmoid steepness. Defaults to 100.\n        lambda1 (float, optional): LASSO/L1 regularisation coefficient. Defaults to 0.\n        lambda2 (float, optional): Ridge/L2 regularisation coefficient. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n\n    Returns:\n        float: Loss value.\n    \"\"\"\n    epsilon *= epsilon\n    residual2 = ((X @ alpha) - Y) ** 2\n    subset = sigmoid(beta * (epsilon - residual2))\n    loss = 0.0\n    if weight is None:\n        residual2 = np.minimum(0, residual2 - epsilon * len(Y))\n        loss += np.sum(subset * residual2) / len(Y)\n    else:\n        sumw = np.sum(weight)\n        residual2 = np.minimum(0, residual2 - epsilon * sumw)\n        loss += np.sum(subset * residual2 * weight) / sumw\n    if lambda1 &gt; 0:\n        loss += lambda1 * np.sum(np.abs(alpha))\n    if lambda2 &gt; 0:\n        loss += lambda2 * np.sum(alpha * alpha)\n    return loss\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.loss_residuals","title":"<code>loss_residuals(alpha, residuals2, epsilon2, beta=100.0, lambda1=0.0, lambda2=0.0, weight=None)</code>","text":"<p>Smoothed version of the SLISE loss (slise.optimisation.loss_smooth), that takes already calculated residuals.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Linear model coefficients.</p> required <code>residuals2</code> <code>ndarray</code> <p>Squared residuals.</p> required <code>epsilon2</code> <code>float</code> <p>Squared error tolerance.</p> required <code>beta</code> <code>float</code> <p>Sigmoid steepness. Defaults to 100.</p> <code>100.0</code> <code>lambda1</code> <code>float</code> <p>LASSO/L1 regularisation coefficient. Defaults to 0.</p> <code>0.0</code> <code>lambda2</code> <code>float</code> <p>Ridge/L2 regularisation coefficient. Defaults to 0.</p> <code>0.0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Loss value.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def loss_residuals(\n    alpha: np.ndarray,\n    residuals2: np.ndarray,\n    epsilon2: float,\n    beta: float = 100.0,\n    lambda1: float = 0.0,\n    lambda2: float = 0.0,\n    weight: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Smoothed version of the SLISE loss ([slise.optimisation.loss_smooth][]), that takes already calculated residuals.\n\n    Args:\n        alpha (np.ndarray): Linear model coefficients.\n        residuals2 (np.ndarray): Squared residuals.\n        epsilon2 (float): Squared error tolerance.\n        beta (float, optional): Sigmoid steepness. Defaults to 100.\n        lambda1 (float, optional): LASSO/L1 regularisation coefficient. Defaults to 0.\n        lambda2 (float, optional): Ridge/L2 regularisation coefficient. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n\n    Returns:\n        float: Loss value.\n    \"\"\"\n    alpha = np.ascontiguousarray(alpha, dtype=np.float64)\n    residuals2 = np.ascontiguousarray(residuals2, dtype=np.float64)\n    lambda1 = float(lambda1)\n    lambda2 = float(lambda2)\n    epsilon2 = float(epsilon2)\n    beta = float(beta)\n    if weight is None:\n        return _loss_residuals(alpha, residuals2, epsilon2, beta, lambda1, lambda2)\n    else:\n        weight = np.ascontiguousarray(weight, dtype=np.float64)\n        return _loss_residualsw(\n            alpha, residuals2, epsilon2, beta, lambda1, lambda2, weight\n        )\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.loss_sharp","title":"<code>loss_sharp(alpha, X, Y, epsilon, lambda1=0, lambda2=0, weight=None)</code>","text":"<p>Exact version (no sigmoid smoothing) of the SLISE loss.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Linear model coefficients.</p> required <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>lambda1</code> <code>float</code> <p>LASSO/L1 regularisation coefficient. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>Ridge/L2 regularisation coefficient. Defaults to 0.</p> <code>0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Loss value.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def loss_sharp(\n    alpha: np.ndarray,\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    weight: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Exact version (no sigmoid smoothing) of the SLISE loss.\n\n    Args:\n        alpha (np.ndarray): Linear model coefficients.\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float): Error tolerance.\n        lambda1 (float, optional): LASSO/L1 regularisation coefficient. Defaults to 0.\n        lambda2 (float, optional): Ridge/L2 regularisation coefficient. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n\n    Returns:\n        float: Loss value.\n    \"\"\"\n    epsilon *= epsilon\n    residual2 = (Y - mat_mul_inter(X, alpha)) ** 2\n    if weight is None:\n        loss = np.sum(residual2[residual2 &lt;= epsilon] - (epsilon * len(Y))) / len(Y)\n    else:\n        sumw = np.sum(weight)\n        mask = residual2 &lt;= epsilon\n        loss = np.sum((residual2[mask] - (epsilon * sumw)) * weight[mask]) / sumw\n    if lambda1 &gt; 0:\n        loss += lambda1 * np.sum(np.abs(alpha))\n    if lambda2 &gt; 0:\n        loss += lambda2 * np.sum(alpha * alpha)\n    return loss\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.loss_grad","title":"<code>loss_grad(alpha, X, Y, epsilon, beta, lambda1=0.0, lambda2=0.0, weight=None)</code>","text":"<p>Smoothed version of the SLISE loss (slise.optimisation.loss_smooth), that also calculates the gradient.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Linear model coefficients.</p> required <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>beta</code> <code>float</code> <p>Sigmoid steepness.</p> required <code>lambda1</code> <code>float</code> <p>Lasso/L1 regularisation coefficient. Defaults to 0.0.</p> <code>0.0</code> <code>lambda2</code> <code>float</code> <p>Ridge/L2 regularisation coefficient. Defaults to 0.0.</p> <code>0.0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, ndarray]</code> <p>Tuple[float, np.ndarray]: Loss value and gradient vector.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def loss_grad(\n    alpha: np.ndarray,\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    beta: float,\n    lambda1: float = 0.0,\n    lambda2: float = 0.0,\n    weight: Optional[np.ndarray] = None,\n) -&gt; Tuple[float, np.ndarray]:\n    \"\"\"Smoothed version of the SLISE loss ([slise.optimisation.loss_smooth][]), that also calculates the gradient.\n\n    Args:\n        alpha (np.ndarray): Linear model coefficients.\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float): Error tolerance.\n        beta (float): Sigmoid steepness.\n        lambda1 (float): Lasso/L1 regularisation coefficient. Defaults to 0.0.\n        lambda2 (float): Ridge/L2 regularisation coefficient. Defaults to 0.0.\n        weight (Optional[np.ndarray]): Weight vector for the data items. Defaults to None.\n\n    Returns:\n        Tuple[float, np.ndarray]: Loss value and gradient vector.\n    \"\"\"\n    alpha = np.ascontiguousarray(alpha, dtype=np.float64)\n    X = np.ascontiguousarray(X, dtype=np.float64)\n    Y = np.ascontiguousarray(Y, dtype=np.float64)\n    assert X.shape[0] == len(Y), f\"Different lengths {X.shape[0]} != {len(Y)}\"\n    assert X.shape[1] == len(alpha), f\"Different lengths {X.shape[0]} != {len(alpha)}\"\n    lambda1 = float(lambda1)\n    lambda2 = float(lambda2)\n    epsilon = float(epsilon)\n    beta = float(beta)\n    if weight is None:\n        loss, grad = _loss_grad(alpha, X, Y, epsilon, beta, lambda2)\n    else:\n        weight = np.ascontiguousarray(weight, dtype=np.float64)\n        assert Y.shape == weight.shape, f\"Different shapes {Y.shape} != {weight.shape}\"\n        loss, grad = _loss_gradw(alpha, X, Y, epsilon, beta, lambda2, weight)\n    if lambda1 &gt; 0:\n        loss = loss + lambda1 * np.sum(np.abs(alpha))\n        grad = grad + lambda1 * np.sign(alpha)\n    return loss, grad\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.owlqn","title":"<code>owlqn(loss_grad_fn, x0, lambda1=0, max_iterations=200, **kwargs)</code>","text":"<p>Wrapper around owlqn that converts max_iter errors to warnings (see <code>lbfgs.fmin_lbfgs</code> from PyLBFGS).</p> <p>Parameters:</p> Name Type Description Default <code>loss_grad_fn</code> <code>Callable[[ndarray], Tuple[float, ndarray]]</code> <p>Function that calculates the loss and gradient.</p> required <code>x0</code> <code>ndarray</code> <p>Initial vector to be optimised.</p> required <code>lambda1</code> <code>float</code> <p>LASSO/L1 regularisation coefficient. Defaults to 1e-6.</p> <code>0</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of optimisation steps. Defaults to 200.</p> <code>200</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Optimised vector.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def owlqn(\n    loss_grad_fn: Callable[[np.ndarray], Tuple[float, np.ndarray]],\n    x0: np.ndarray,\n    lambda1: float = 0,\n    max_iterations: int = 200,\n    **kwargs,\n) -&gt; np.ndarray:\n    \"\"\"Wrapper around owlqn that converts max_iter errors to warnings (see `lbfgs.fmin_lbfgs` from PyLBFGS).\n\n    Args:\n        loss_grad_fn (Callable[[np.ndarray], Tuple[float, np.ndarray]]): Function that calculates the loss and gradient.\n        x0 (np.ndarray): Initial vector to be optimised.\n        lambda1 (float, optional): LASSO/L1 regularisation coefficient. Defaults to 1e-6.\n        max_iterations (int, optional): Maximum number of optimisation steps. Defaults to 200.\n\n    Returns:\n        np.ndarray: Optimised vector.\n    \"\"\"\n\n    def f(x: np.ndarray, gradient: np.ndarray) -&gt; float:\n        loss, grad = loss_grad_fn(x)\n        gradient[:] = grad\n        return loss\n\n    try:  # PyLBFGS throws an error if max_iterations is exceeded, this is a workaround to convert it into a warning\n\n        def p(x, g, fx, xnorm, gnorm, step, k, num_eval, *args):\n            if k &gt;= max_iterations:\n                x0[:] = x\n\n        x0 = fmin_lbfgs(\n            f=f,\n            x0=x0,\n            progress=p,\n            orthantwise_c=lambda1,\n            max_iterations=max_iterations,\n            line_search=\"wolfe\" if lambda1 &gt; 0 else \"default\",\n            **kwargs,\n        )\n    except LBFGSError as error:\n        if (\n            error.args[0]\n            != \"The algorithm routine reaches the maximum number of iterations.\"\n        ):\n            raise error\n        else:\n            warn(\n                \"LBFGS optimisation reaches the maximum number of iterations.\",\n                SliseWarning,\n            )\n    return x0\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.regularised_regression","title":"<code>regularised_regression(X, Y, lambda1=1e-06, lambda2=1e-06, weight=None, max_iterations=200)</code>","text":"<p>Train a linear regression model with lasso (L1) and/or ridge (L2) regularisation.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>lambda1</code> <code>float</code> <p>LASSO/L1 regularisation coefficient. Defaults to 1e-6.</p> <code>1e-06</code> <code>lambda2</code> <code>float</code> <p>Ridge/L2 regularisation coefficient. Defaults to 1e-6.</p> <code>1e-06</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of optimisation steps. Defaults to 200.</p> <code>200</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The coefficients of the linear model.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def regularised_regression(\n    X: np.ndarray,\n    Y: np.ndarray,\n    lambda1: float = 1e-6,\n    lambda2: float = 1e-6,\n    weight: Optional[np.ndarray] = None,\n    max_iterations: int = 200,\n) -&gt; np.ndarray:\n    \"\"\"Train a linear regression model with lasso (L1) and/or ridge (L2) regularisation.\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        lambda1 (float, optional): LASSO/L1 regularisation coefficient. Defaults to 1e-6.\n        lambda2 (float, optional): Ridge/L2 regularisation coefficient. Defaults to 1e-6.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        max_iterations (int, optional): Maximum number of optimisation steps. Defaults to 200.\n\n    Returns:\n        np.ndarray: The coefficients of the linear model.\n    \"\"\"\n    X = np.ascontiguousarray(X, dtype=np.float64)\n    Y = np.ascontiguousarray(Y, dtype=np.float64)\n    lambda1 = float(lambda1)\n    lambda2 = float(lambda2)\n    assert X.shape[0] == len(Y), f\"Different lengths {X.shape[0]} != {len(Y)}\"\n    if weight is None:\n        lf = lambda alpha: _ridge_numba(alpha, X, Y, lambda2)  # noqa: E731\n    else:\n        weight = np.ascontiguousarray(weight, dtype=np.float64)\n        assert Y.shape == weight.shape, f\"Different shapes {Y.shape} != {weight.shape}\"\n        lf = lambda alpha: _ridge_numbaw(alpha, X, Y, lambda2, weight)  # noqa: E731\n    return owlqn(lf, np.zeros(X.shape[1], dtype=np.float64), lambda1, max_iterations)\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.optimise_loss","title":"<code>optimise_loss(alpha, X, Y, epsilon=0.1, beta=100, lambda1=0, lambda2=0, weight=None, max_iterations=200)</code>","text":"<p>Optimise a smoothed SLISE loss with <code>owl-qn</code>.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Linear model coefficients.</p> required <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Target vector</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance. Defaults to 0.1.</p> <code>0.1</code> <code>beta</code> <code>float</code> <p>Sigmoid steepness. Defaults to 100.</p> <code>100</code> <code>lambda1</code> <code>float</code> <p>LASSO/L1 regularisation coefficient. Defaults to 1e-6.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>Ridge/L2 regularisation coefficient. Defaults to 1e-6.</p> <code>0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of optimisation steps. Defaults to 200.</p> <code>200</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The coefficients of the linear model.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def optimise_loss(\n    alpha: np.ndarray,\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float = 0.1,\n    beta: float = 100,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    weight: Optional[np.ndarray] = None,\n    max_iterations: int = 200,\n) -&gt; np.ndarray:\n    \"\"\"Optimise a smoothed SLISE loss with `owl-qn`.\n\n    Args:\n        alpha (np.ndarray): Linear model coefficients.\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Target vector\n        epsilon (float, optional): Error tolerance. Defaults to 0.1.\n        beta (float, optional): Sigmoid steepness. Defaults to 100.\n        lambda1 (float, optional): LASSO/L1 regularisation coefficient. Defaults to 1e-6.\n        lambda2 (float, optional): Ridge/L2 regularisation coefficient. Defaults to 1e-6.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        max_iterations (int, optional): Maximum number of optimisation steps. Defaults to 200.\n\n    Returns:\n        np.ndarray: The coefficients of the linear model.\n    \"\"\"\n    alpha = np.ascontiguousarray(alpha, dtype=np.float64)\n    X = np.ascontiguousarray(X, dtype=np.float64)\n    Y = np.ascontiguousarray(Y, dtype=np.float64)\n    assert X.shape[0] == len(Y), f\"Different lengths {X.shape[0]} != {len(Y)}\"\n    assert X.shape[1] == len(alpha), f\"Different lengths {X.shape[0]} != {len(alpha)}\"\n    lambda1 = float(lambda1)\n    lambda2 = float(lambda2)\n    epsilon = float(epsilon)\n    beta = float(beta)\n    if weight is None:\n        lf = lambda alpha: _loss_grad(alpha, X, Y, epsilon, beta, lambda2)  # noqa: E731\n    else:\n        weight = np.ascontiguousarray(weight, dtype=np.float64)\n        assert Y.shape == weight.shape, f\"Different shapes {Y.shape} != {weight.shape}\"\n        lf = lambda alpha: _loss_gradw(alpha, X, Y, epsilon, beta, lambda2, weight)  # noqa: E731\n    return owlqn(lf, alpha, lambda1, max_iterations)\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.log_approximation_ratio","title":"<code>log_approximation_ratio(residuals2, epsilon2, beta1, beta2, weight=None)</code>","text":"<p>Calculate log(K), where K is the approximation ratio between two smoothed losses.</p> <p>Parameters:</p> Name Type Description Default <code>residuals2</code> <code>ndarray</code> <p>Squared residuals.</p> required <code>epsilon2</code> <code>float</code> <p>Squared error tolerance.</p> required <code>beta1</code> <code>float</code> <p>Old sigmoid steepness.</p> required <code>beta2</code> <code>float</code> <p>New sigmoid steepness.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>log of the approximation ratio between <code>beta1</code> and <code>beta2</code> for the current solution.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def log_approximation_ratio(\n    residuals2: np.ndarray,\n    epsilon2: float,\n    beta1: float,\n    beta2: float,\n    weight: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Calculate log(K), where K is the approximation ratio between two smoothed losses.\n\n    Args:\n        residuals2 (np.ndarray): Squared residuals.\n        epsilon2 (float): Squared error tolerance.\n        beta1 (float): Old sigmoid steepness.\n        beta2 (float): New sigmoid steepness.\n        weight (Optional[np.ndarray], optional): Weight vector. Defaults to None.\n\n    Returns:\n        float: log of the approximation ratio between `beta1` and `beta2` for the current solution.\n    \"\"\"\n    if beta1 &gt;= beta2:\n        return 0\n    log_f = lambda r, beta: log_sigmoid(beta * (epsilon2 - r))  # noqa: E731\n    dlog_g = lambda r: -beta1 * dlog_sigmoid(  # noqa: E731\n        beta1 * (epsilon2 - r)\n    ) + beta2 * dlog_sigmoid(beta2 * (epsilon2 - r))\n    if dlog_g(0) &lt; 0:\n        a = brentq(dlog_g, 0, epsilon2)\n        log_k = min(\n            log_f(0, beta1) - log_f(0, beta2), log_f(a, beta1) - log_f(a, beta2)\n        )\n    else:\n        log_k = log_f(0, beta1) - log_f(0, beta2)\n    if weight is None:\n        phi = np.maximum(0, epsilon2 - residuals2 / len(residuals2))\n    else:\n        phi = np.maximum(0, epsilon2 - residuals2 / np.sum(weight)) * weight\n    log_K = (\n        log_sum_special(log_f(residuals2, beta1), phi)\n        - log_k\n        - log_sum_special(log_f(residuals2, beta2), phi)\n    )\n    return log_K\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.next_beta","title":"<code>next_beta(residuals2, epsilon2=0.01, beta=0.0, weight=None, beta_max=2500, log_max_approx=0.14, min_beta_step=0.0005)</code>","text":"<p>Calculate the next beta for the graduated optimisation.</p> <p>Parameters:</p> Name Type Description Default <code>residuals2</code> <code>ndarray</code> <p>Squared residuals.</p> required <code>epsilon2</code> <code>float</code> <p>Squared error tolerance. Defaults to 0.01.</p> <code>0.01</code> <code>beta</code> <code>float</code> <p>Sigmoid steepness. Defaults to 0.</p> <code>0.0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>Maximum <code>beta</code>. Defaults to 2500.</p> <code>2500</code> <code>log_max_approx</code> <code>float</code> <p>Log-maximum approximation ratio. Defaults to 0.14.</p> <code>0.14</code> <code>min_beta_step</code> <code>float</code> <p>Minimum increase of <code>beta</code>. Defaults to 0.0005.</p> <code>0.0005</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>next <code>beta</code>.</p> Source code in <code>slise/optimisation.py</code> <pre><code>def next_beta(\n    residuals2: np.ndarray,\n    epsilon2: float = 0.01,\n    beta: float = 0.0,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 2500,\n    log_max_approx: float = 0.14,\n    min_beta_step: float = 0.0005,\n) -&gt; float:\n    \"\"\"Calculate the next beta for the graduated optimisation.\n\n    Args:\n        residuals2 (np.ndarray): Squared residuals.\n        epsilon2 (float): Squared error tolerance. Defaults to 0.01.\n        beta (float): Sigmoid steepness. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector. Defaults to None.\n        beta_max (float, optional): Maximum `beta`. Defaults to 2500.\n        log_max_approx (float, optional): Log-maximum approximation ratio. Defaults to 0.14.\n        min_beta_step (float, optional): Minimum increase of `beta`. Defaults to 0.0005.\n\n    Returns:\n        float: next `beta`.\n    \"\"\"\n    if beta &gt;= beta_max:\n        return beta\n    log_approx = log_approximation_ratio(residuals2, epsilon2, beta, beta_max, weight)\n    if log_approx &lt;= log_max_approx:\n        return beta_max\n    else:\n        f = (  # noqa: E731\n            lambda b: log_approximation_ratio(residuals2, epsilon2, beta, b, weight)\n            - log_max_approx\n        )\n        beta_min = beta + min_beta_step * (beta_max + beta)\n        return max(brentq(f, beta, beta_max), beta_min)\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.matching_epsilon","title":"<code>matching_epsilon(residuals2, epsilon2, beta, weight=None)</code>","text":"<p>Approximately calculate the epsilon that minimises the approximation ratio to the exact loss.</p> <p>Parameters:</p> Name Type Description Default <code>residuals2</code> <code>ndarray</code> <p>Squared residuals.</p> required <code>epsilon2</code> <code>float</code> <p>Squared error tolerance.</p> required <code>beta</code> <code>float</code> <p>Sigmoid steepness.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>(Approximatively) optimal epsilon for the exact loss (for the current solution).</p> Source code in <code>slise/optimisation.py</code> <pre><code>def matching_epsilon(\n    residuals2: np.ndarray,\n    epsilon2: float,\n    beta: float,\n    weight: Optional[np.ndarray] = None,\n) -&gt; float:\n    \"\"\"Approximately calculate the epsilon that minimises the approximation ratio to the exact loss.\n\n    Args:\n        residuals2 (np.ndarray): Squared residuals.\n        epsilon2 (float): Squared error tolerance.\n        beta (float): Sigmoid steepness.\n        weight (Optional[np.ndarray], optional): Weight vector. Defaults to None.\n\n    Returns:\n        float: (Approximatively) optimal epsilon for the exact loss (for the current solution).\n    \"\"\"\n    if weight is None:\n        residuals2 = np.sort(residuals2)\n        loss = sigmoid(beta * (epsilon2 - residuals2))\n        i = np.argmax(np.arange(1, 1 + len(residuals2)) * loss)\n        return residuals2[i] ** 0.5\n    else:\n        order = np.argsort(residuals2)\n        residuals2 = residuals2[order]\n        loss = sigmoid(beta * (epsilon2 - residuals2))\n        i = np.argmax(np.cumsum(weight[order]) * loss)\n        return residuals2[i] ** 0.5\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.graduated_optimisation","title":"<code>graduated_optimisation(alpha, X, Y, epsilon, beta=0, lambda1=0, lambda2=0, weight=None, beta_max=20, max_approx=1.15, max_iterations=200, debug=False)</code>","text":"<p>Optimise <code>alpha</code> using graduated optimisation.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Initial linear model coefficients.</p> required <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>beta</code> <code>float</code> <p>Initial sigmoid steepness. Defaults to 0.</p> <code>0</code> <code>lambda1</code> <code>float</code> <p>L1 regularisation strength. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>L2 regularisation strength. Defaults to 0.</p> <code>0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>beta_max</code> <code>float</code> <p>Maximum sigmoid steepness (the final beta). Defaults to 20.</p> <code>20</code> <code>max_approx</code> <code>float</code> <p>Target approximation ratio when increasing beta. Defaults to 1.15.</p> <code>1.15</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of iterations for owl-qn. Defaults to 200.</p> <code>200</code> <code>debug</code> <code>bool</code> <p>Print debug logs after each optimisation step. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Optimised <code>alpha</code>.</p> Source code in <code>slise/optimisation.py</code> <pre><code>@np.errstate(over=\"ignore\")\ndef graduated_optimisation(\n    alpha: np.ndarray,\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    beta: float = 0,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    weight: Optional[np.ndarray] = None,\n    beta_max: float = 20,\n    max_approx: float = 1.15,\n    max_iterations: int = 200,\n    debug: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Optimise `alpha` using graduated optimisation.\n\n    Args:\n        alpha (np.ndarray): Initial linear model coefficients.\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float): Error tolerance.\n        beta (float, optional): Initial sigmoid steepness. Defaults to 0.\n        lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n        lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        beta_max (float, optional): Maximum sigmoid steepness (the final beta). Defaults to 20.\n        max_approx (float, optional): Target approximation ratio when increasing beta. Defaults to 1.15.\n        max_iterations (int, optional): Maximum number of iterations for owl-qn. Defaults to 200.\n        debug (bool, optional): Print debug logs after each optimisation step. Defaults to False.\n\n    Returns:\n        np.ndarray: Optimised `alpha`.\n    \"\"\"\n    X = np.ascontiguousarray(X, dtype=np.float64)\n    Y = np.ascontiguousarray(Y, dtype=np.float64)\n    if weight is not None:\n        weight = np.ascontiguousarray(weight, dtype=np.float64)\n    beta_max = beta_max / epsilon**2\n    max_approx = log(max_approx)\n    with catch_warnings(record=True) as w:\n        while beta &lt; beta_max:\n            alpha = optimise_loss(\n                alpha, X, Y, epsilon, beta, lambda1, lambda2, weight, max_iterations\n            )\n            if debug:\n                _debug_log(alpha, X, Y, epsilon, beta, lambda1, lambda2, weight)\n            beta = next_beta(\n                (X @ alpha - Y) ** 2, epsilon**2, beta, weight, beta_max, max_approx\n            )\n    alpha = optimise_loss(\n        alpha, X, Y, epsilon, beta, lambda1, lambda2, weight, max_iterations * 4\n    )\n    if debug:\n        _debug_log(alpha, X, Y, epsilon, beta, lambda1, lambda2, weight)\n        if w:\n            print(\"Warnings from intermediate steps:\", w)\n    return alpha\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.set_threads","title":"<code>set_threads(num=-1)</code>","text":"<p>Set the number of numba threads.</p> <p>Parameters:</p> Name Type Description Default <code>num</code> <code>int</code> <p>The number of threads (or -1 to keep the old value). Defaults to -1.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The old number of theads (or -1 if unchanged).</p> Source code in <code>slise/optimisation.py</code> <pre><code>def set_threads(num: int = -1) -&gt; int:\n    \"\"\"Set the number of numba threads.\n\n    Args:\n        num (int, optional): The number of threads (or -1 to keep the old value). Defaults to -1.\n\n    Returns:\n        int: The old number of theads (or -1 if unchanged).\n    \"\"\"\n    if num &gt; 0:\n        old = get_num_threads()\n        if old != num:\n            set_num_threads(num)\n        return old\n    return -1\n</code></pre>"},{"location":"docs/slise.optimisation/#slise.optimisation.check_threading_layer","title":"<code>check_threading_layer()</code>","text":"<p>Check which numba threading_layer is active, and warn if it is \"workqueue\".</p> Source code in <code>slise/optimisation.py</code> <pre><code>def check_threading_layer():\n    \"\"\"\n    Check which numba threading_layer is active, and warn if it is \"workqueue\".\n    \"\"\"\n    _dummy_numba(np.ones(1))\n    try:\n        if threading_layer() == \"workqueue\":\n            warn(\n                'Using `numba.threading_layer()==\"workqueue\"` can be devastatingly slow!'\n                \" See https://numba.pydata.org/numba-doc/latest/user/threading-layer.html for alternatives.\",\n                SliseWarning,\n            )\n    except ValueError as e:\n        warn(f\"Numba: {e}\", SliseWarning)\n</code></pre>"},{"location":"docs/slise.plot/","title":"slise.plot","text":""},{"location":"docs/slise.plot/#slise.plot","title":"<code>slise.plot</code>","text":"<p>This script contains functions for plotting SLISE solutions.</p>"},{"location":"docs/slise.plot/#slise.plot.fill_column_names","title":"<code>fill_column_names(names=None, amount=-1, intercept=False)</code>","text":"<p>Make sure the list of column names is of the correct size.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>Optional[List[str]]</code> <p>Prefilled list of column names. Defaults to None.</p> <code>None</code> <code>amount</code> <code>int</code> <p>Number of columns. Defaults to -1.</p> <code>-1</code> <code>intercept</code> <code>bool</code> <p>Should an intercept column be added. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of column names.</p> Source code in <code>slise/plot.py</code> <pre><code>def fill_column_names(\n    names: Optional[List[str]] = None, amount: int = -1, intercept: bool = False\n) -&gt; List[str]:\n    \"\"\"Make sure the list of column names is of the correct size.\n\n    Args:\n        names (Optional[List[str]], optional): Prefilled list of column names. Defaults to None.\n        amount (int, optional): Number of columns. Defaults to -1.\n        intercept (bool, optional): Should an intercept column be added. Defaults to False.\n\n    Returns:\n        List[str]: List of column names.\n    \"\"\"\n    if amount &lt; 1:\n        return names\n    if names is None:\n        if intercept:\n            return [\"Intercept\"] + [\"Variable %d\" % i for i in range(amount)]\n        else:\n            return [\"Variable %d\" % i for i in range(amount)]\n    if len(names) &gt; amount:\n        warn(\"Too many column names given\", SliseWarning)\n        names = names[:amount]\n    if len(names) &lt; amount:\n        warn(\"Too few column names given\", SliseWarning)\n        names = names + [\"Variable %d\" % i for i in range(len(names), amount)]\n    if intercept:\n        return [\"Intercept\"] + names\n    else:\n        return names\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.fill_prediction_str","title":"<code>fill_prediction_str(y, Y=None, classes=None, decimals=3)</code>","text":"<p>Create a string describing the prediction</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>float</code> <p>The prediction.</p> required <code>Y</code> <code>Optional[ndarray]</code> <p>Vector of predictions (used to guess if the predictions are probabilities). Defaults to None.</p> <code>None</code> <code>classes</code> <code>Union[List[str], str, None]</code> <p>List of class names (starting with the negative class), or singular class name. Defaults to None.</p> <code>None</code> <code>decimals</code> <code>int</code> <p>How many decimals hsould be written. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Description of the prediction.</p> Source code in <code>slise/plot.py</code> <pre><code>def fill_prediction_str(\n    y: float,\n    Y: Optional[np.ndarray] = None,\n    classes: Union[List[str], str, None] = None,\n    decimals: int = 3,\n) -&gt; str:\n    \"\"\"Create a string describing the prediction\n\n    Args:\n        y (float): The prediction.\n        Y (Optional[np.ndarray]): Vector of predictions (used to guess if the predictions are probabilities). Defaults to None.\n        classes (Union[List[str], str, None], optional): List of class names (starting with the negative class), or singular class name. Defaults to None.\n        decimals (int, optional): How many decimals hsould be written. Defaults to 3.\n\n    Returns:\n        str: Description of the prediction.\n    \"\"\"\n    if classes is not None:\n        prob = Y is not None and (0 &lt;= Y.min() &lt; 0.5) and (0.5 &lt; Y.max() &lt;= 1)\n        if isinstance(classes, str):\n            if prob:\n                return f\"Predicted: {y*100:.{decimals}f}% {classes[0]}\"\n            else:\n                return f\"Predicted: {y:.{decimals}f} {classes}\"\n        else:\n            if prob:\n                if y &gt; 0.5:\n                    return f\"Predicted: {y*100:.{decimals}f}% {classes[1]}\"\n                else:\n                    return f\"Predicted: {(1-y)*100:.{decimals}f}% {classes[0]}\"\n            else:\n                if y &gt; 0:\n                    return f\"Predicted: {y:.{decimals}f} {classes[1]}\"\n                else:\n                    return f\"Predicted: {-y:.{decimals}f} {classes[0]}\"\n    else:\n        return f\"Predicted: {y:.{decimals}f}\"\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.extended_limits","title":"<code>extended_limits(x, extension=0.05, steps=2)</code>","text":"<p>Create limits that extend a fraction larger than the data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The data.</p> required <code>extension</code> <code>float</code> <p>How much should the limits extend. Defaults to 0.05.</p> <code>0.05</code> <code>steps</code> <code>int</code> <p>Number of points in the limit. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The limit as a vector of points.</p> Source code in <code>slise/plot.py</code> <pre><code>def extended_limits(\n    x: np.ndarray, extension: float = 0.05, steps: int = 2\n) -&gt; np.ndarray:\n    \"\"\"Create limits that extend a fraction larger than the data.\n\n    Args:\n        x (np.ndarray): The data.\n        extension (float, optional): How much should the limits extend. Defaults to 0.05.\n        steps (int, optional): Number of points in the limit. Defaults to 2.\n\n    Returns:\n        np.ndarray: The limit as a vector of points.\n    \"\"\"\n    min = np.min(x)\n    max = np.max(x)\n    diff = max - min\n    if steps &lt;= 2:\n        return np.array([min - diff * extension, max + diff * extension])\n    else:\n        return np.linspace(min - diff * extension, max + diff * extension, steps)\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.get_explanation_order","title":"<code>get_explanation_order(alpha, intercept=True, min=5, max=-1, th=1e-06)</code>","text":"<p>Get the order in which to show the variables in the plots.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>ndarray</code> <p>Linear model.</p> required <code>intercept</code> <code>bool</code> <p>Does the model include an intercept. Defaults to True.</p> <code>True</code> <code>min</code> <code>int</code> <p>If the number of variables is larger than this, hide the zeroes. Defaults to 5.</p> <code>5</code> <code>max</code> <code>int</code> <p>If <code>max &gt; 0</code>, select the top variables. Defaults to -1.</p> <code>-1</code> <code>th</code> <code>[type]</code> <p>Threshold for zero. Defaults to 1e-6.</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: The order of the variables in the explanation</p> Source code in <code>slise/plot.py</code> <pre><code>def get_explanation_order(\n    alpha: np.ndarray,\n    intercept: bool = True,\n    min: int = 5,\n    max: int = -1,\n    th: float = 1e-6,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Get the order in which to show the variables in the plots.\n\n    Args:\n        alpha (np.ndarray): Linear model.\n        intercept (bool, optional): Does the model include an intercept. Defaults to True.\n        min (int, optional): If the number of variables is larger than this, hide the zeroes. Defaults to 5.\n        max (int, optional): If `max &gt; 0`, select the top variables. Defaults to -1.\n        th ([type], optional): Threshold for zero. Defaults to 1e-6.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: The order of the variables in the explanation\n    \"\"\"\n    if intercept:\n        order = np.argsort(alpha[1:]) + 1\n    else:\n        order = np.argsort(alpha)\n    if len(order) &gt; min:\n        order = order[np.nonzero(alpha[order])]\n        if len(order) &gt; min:\n            order = order[np.abs(alpha[order]) &gt; np.max(np.abs(alpha)) * th]\n    if max &gt; 0 and len(order) &gt; max:\n        nth = -np.partition(-np.abs(alpha), max - 1)[max - 1]\n        order = order[np.abs(alpha[order]) &gt;= nth]\n    if intercept:\n        order = np.concatenate((order, np.zeros(1, order.dtype)))\n    return np.flip(order)\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.print_slise","title":"<code>print_slise(coefficients, intercept, subset, loss, epsilon, variables=None, title='SLISE', decimals=3, num_var=10, unscaled=None, unscaled_y=None, terms=None, scaled=None, alpha=None, scaled_terms=None, classes=None, unscaled_preds=None, logit=False)</code>","text":"<p>Print the results from SLISE.</p> <p>Parameters:</p> Name Type Description Default <code>coefficients</code> <code>ndarray</code> <p>The linear model coefficients.</p> required <code>intercept</code> <code>bool</code> <p>Is the first coefficient an intercept.</p> required <code>subset</code> <code>ndarray</code> <p>Subset mask.</p> required <code>loss</code> <code>float</code> <p>SLISE loss.</p> required <code>epsilon</code> <code>float</code> <p>(Unscaled) error tolerance.</p> required <code>variables</code> <code>Optional[List[str]]</code> <p>Variable names. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title to print first. Defaults to \"SLISE\".</p> <code>'SLISE'</code> <code>decimals</code> <code>int</code> <p>Number of decimals to print. Defaults to 3.</p> <code>3</code> <code>num_var</code> <code>int</code> <p>Exclude zero weights if there are too many variables. Defaults to 10.</p> <code>10</code> <code>unscaled</code> <code>Optional[ndarray]</code> <p>Unscaled x (explained item). Defaults to None.</p> <code>None</code> <code>unscaled_y</code> <code>Union[None, float]</code> <p>Unscaled y (explained outcome). Defaults to None.</p> <code>None</code> <code>terms</code> <code>Optional[ndarray]</code> <p>Unscaled terms (coefficients * x). Defaults to None.</p> <code>None</code> <code>scaled</code> <code>Optional[ndarray]</code> <p>Scaled x (explained item). Defaults to None.</p> <code>None</code> <code>alpha</code> <code>Optional[ndarray]</code> <p>Scaled model. Defaults to None.</p> <code>None</code> <code>scaled_terms</code> <code>Optional[ndarray]</code> <p>Scaled terms (alpha * scaled_x). Defaults to None.</p> <code>None</code> <code>classes</code> <code>Optional[List[str]]</code> <p>Class names (if applicable). Defaults to None.</p> <code>None</code> <code>unscaled_preds</code> <code>Optional[ndarray]</code> <p>Unscaled resonse (Y-vector). Defaults to None.</p> <code>None</code> <code>logit</code> <code>bool</code> <p>A logit transformation has been applied. Defaults to False.</p> <code>False</code> Source code in <code>slise/plot.py</code> <pre><code>def print_slise(\n    coefficients: np.ndarray,\n    intercept: bool,\n    subset: np.ndarray,\n    loss: float,\n    epsilon: float,\n    variables: Optional[List[str]] = None,\n    title: str = \"SLISE\",\n    decimals: int = 3,\n    num_var: int = 10,\n    unscaled: Optional[np.ndarray] = None,\n    unscaled_y: Union[None, float] = None,\n    terms: Optional[np.ndarray] = None,\n    scaled: Optional[np.ndarray] = None,\n    alpha: Optional[np.ndarray] = None,\n    scaled_terms: Optional[np.ndarray] = None,\n    classes: Optional[List[str]] = None,\n    unscaled_preds: Optional[np.ndarray] = None,\n    logit: bool = False,\n):\n    \"\"\"Print the results from SLISE.\n\n    Args:\n        coefficients (np.ndarray): The linear model coefficients.\n        intercept (bool): Is the first coefficient an intercept.\n        subset (np.ndarray): Subset mask.\n        loss (float): SLISE loss.\n        epsilon (float): (Unscaled) error tolerance.\n        variables (Optional[List[str]], optional): Variable names. Defaults to None.\n        title (str, optional): Title to print first. Defaults to \"SLISE\".\n        decimals (int, optional): Number of decimals to print. Defaults to 3.\n        num_var (int, optional): Exclude zero weights if there are too many variables. Defaults to 10.\n        unscaled (Optional[np.ndarray], optional): Unscaled x (explained item). Defaults to None.\n        unscaled_y (Union[None, float], optional): Unscaled y (explained outcome). Defaults to None.\n        terms (Optional[np.ndarray], optional): Unscaled terms (coefficients * x). Defaults to None.\n        scaled (Optional[np.ndarray], optional): Scaled x (explained item). Defaults to None.\n        alpha (Optional[np.ndarray], optional): Scaled model. Defaults to None.\n        scaled_terms (Optional[np.ndarray], optional): Scaled terms (alpha * scaled_x). Defaults to None.\n        classes (Optional[List[str]], optional): Class names (if applicable). Defaults to None.\n        unscaled_preds (Optional[np.ndarray], optional): Unscaled resonse (Y-vector). Defaults to None.\n        logit (bool, optional): A logit transformation has been applied. Defaults to False.\n    \"\"\"\n    rows = OrderedDict()\n    rows[\"Variable Names:    \"] = fill_column_names(\n        variables, len(coefficients) - intercept, intercept\n    )\n    if unscaled is not None:\n        rows[\"Explained Item:\"] = [\"\"] + [\"%%.%df\" % decimals % a for a in unscaled]\n        rows[\"Model Weights:\"] = [\"%%.%df\" % decimals % a for a in coefficients]\n    else:\n        rows[\"Coefficients:\"] = [\"%%.%df\" % decimals % a for a in coefficients]\n    if terms is not None:\n        rows[\"Prediction Term:\"] = [\"%%.%df\" % decimals % a for a in terms]\n    if scaled is not None:\n        rows[\"Normalised Item:\"] = [\"\"] + [\"%%.%df\" % decimals % a for a in scaled]\n    if alpha is not None:\n        rows[\"Normalised Weights:\"] = [\"%%.%df\" % decimals % a for a in alpha]\n    if scaled_terms is not None:\n        rows[\"Normalised Term:\"] = [\"%%.%df\" % decimals % a for a in scaled_terms]\n    col_len = [\n        max(8, *vs) + 1\n        for vs in zip(*(tuple(len(v) for v in vs) for vs in rows.values()))\n    ]\n    if len(coefficients) &gt; num_var:\n        col_len = [cl if c != 0 else 0 for cl, c in zip(col_len, coefficients)]\n    lab_len = max(len(r) for r in rows)\n    if title:\n        print(title)\n    if unscaled_y is not None:\n        print(fill_prediction_str(unscaled_y, unscaled_preds, classes, decimals))\n    for k in rows:\n        print(\n            f\"{k:&lt;{lab_len}}\",\n            \" \".join([f\"{s:&gt;{c}}\" for s, c in zip(rows[k], col_len) if c &gt; 0]),\n        )\n    loss = f\"{loss:.{decimals}f}\"\n    epsilon = f\"{epsilon:.{decimals}f}\"\n    subsize = f\"{subset.mean():.{decimals}f}\"\n    col_len = max(len(loss), len(epsilon), len(subsize), 8)\n    print(f\"Loss:          {loss   :&gt;{col_len}}\")\n    print(f\"Subset:        {subsize:&gt;{col_len}}\")\n    print(f\"Epsilon:       {epsilon:&gt;{col_len}}\")\n    if logit and unscaled_preds is not None:\n        if isinstance(classes, list) and len(classes) == 2:\n            print(\n                f\"Class Balance: {(unscaled_preds[subset] &gt; 0.5).mean() * 100:&gt;.{decimals}f}% {classes[0]} | {(unscaled_preds[subset] &lt; 0.5).mean() * 100:&gt;.{decimals}f}% {classes[1]}\"\n            )\n        else:\n            print(\n                f\"Class Balance: {(unscaled_preds[subset] &gt; 0.5).mean() * 100:&gt;.{decimals}f}% | {(unscaled_preds[subset] &lt; 0.5).mean() * 100:&gt;.{decimals}f}%\"\n            )\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.plot_2d","title":"<code>plot_2d(X, Y, model, epsilon, x=None, y=None, logit=False, title='SLISE for Robust Regression', label_x='x', label_y='y', decimals=3, fig=None)</code>","text":"<p>Plot the regression/explanation in a 2D scatter plot with a line for the regression model (and the explained item marked).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>model</code> <code>ndarray</code> <p>Linear model.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>x</code> <code>Optional[ndarray]</code> <p>Explained item. Defaults to None.</p> <code>None</code> <code>y</code> <code>Optional[float]</code> <p>Explained outcome. Defaults to None.</p> <code>None</code> <code>logit</code> <code>bool</code> <p>Should Y be logit-transformed. Defaults to False.</p> <code>False</code> <code>title</code> <code>str</code> <p>Plot title. Defaults to \"SLISE for Robust Regression\".</p> <code>'SLISE for Robust Regression'</code> <code>label_x</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>label_y</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing numbers. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Optional[Figure]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>SliseException</code> <p>If the data has too many dimensions.</p> Source code in <code>slise/plot.py</code> <pre><code>def plot_2d(\n    X: np.ndarray,\n    Y: np.ndarray,\n    model: np.ndarray,\n    epsilon: float,\n    x: Optional[np.ndarray] = None,\n    y: Optional[float] = None,\n    logit: bool = False,\n    title: str = \"SLISE for Robust Regression\",\n    label_x: str = \"x\",\n    label_y: str = \"y\",\n    decimals: int = 3,\n    fig: Optional[Figure] = None,\n):\n    \"\"\"Plot the regression/explanation in a 2D scatter plot with a line for the regression model (and the explained item marked).\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        model (np.ndarray): Linear model.\n        epsilon (float): Error tolerance.\n        x (Optional[np.ndarray], optional): Explained item. Defaults to None.\n        y (Optional[float], optional): Explained outcome. Defaults to None.\n        logit (bool, optional): Should Y be logit-transformed. Defaults to False.\n        title (str, optional): Plot title. Defaults to \"SLISE for Robust Regression\".\n        label_x (str, optional): X-axis label. Defaults to \"x\".\n        label_y (str, optional): Y-axis label. Defaults to \"y\".\n        decimals (int, optional): Number of decimals when writing numbers. Defaults to 3.\n        fig (Optional[Figure], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n\n    Raises:\n        SliseException: If the data has too many dimensions.\n    \"\"\"\n    if fig is None:\n        plot = True\n        fig, ax = plt.subplots()\n    else:\n        ax = fig.subplots()\n        plot = False\n    if X.size != Y.size:\n        raise SliseException(f\"Can only plot 1D data, |Y| = {Y.size} != {X.size} = |X|\")\n    x_limits = extended_limits(X, 0.03, 20 if logit else 2)\n    y_limits = mat_mul_inter(x_limits[:, None], model)\n    if logit:\n        ax.fill_between(\n            x_limits,\n            sigmoid(y_limits + epsilon),\n            sigmoid(y_limits - epsilon),\n            color=SLISE_PURPLE + \"33\",\n            label=\"Subset\",\n        )\n        y_limits = sigmoid(y_limits)\n    else:\n        ax.fill_between(\n            x_limits,\n            y_limits + epsilon,\n            y_limits - epsilon,\n            color=SLISE_PURPLE + \"33\",\n            label=\"Subset\",\n        )\n    ax.plot(X.ravel(), Y, \"o\", color=\"black\", label=\"Dataset\")\n    if x is not None and y is not None:\n        ax.plot(x_limits, y_limits, \"-\", color=SLISE_PURPLE, label=\"Model\")\n        ax.plot(x, y, \"o\", color=SLISE_ORANGE, label=\"Explained Item\")\n    else:\n        ax.plot(x_limits, y_limits, \"-\", color=SLISE_ORANGE, label=\"Model\")\n    formula = \"\"\n    if isinstance(model, float):\n        formula = f\"{model:.{decimals}f} * {label_x}\"\n    elif len(model.flat) == 1:\n        formula = f\"{model.flat[0]:.{decimals}f} * {label_x}\"\n    elif np.abs(model[0]) &gt; 1e-8:\n        sign = \"-\" if model[1] &lt; 0.0 else \"+\"\n        formula = f\"{model[0]:.{decimals}f} {sign} {abs(model[1]):.{decimals}f} $\\\\cdot$ {label_x}\"\n    else:\n        formula = f\"{model[1]:.{decimals}f} * {label_x}\"\n    if logit:\n        formula = f\"$\\\\sigma$({formula})\"\n    ax.legend()\n    ax.set_xlabel(label_x)\n    ax.set_ylabel(label_y)\n    ax.set_title(f\"{title}: {label_y} = {formula}\")\n    fig.tight_layout()\n    if plot:\n        plt.show()\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.plot_dist","title":"<code>plot_dist(X, Y, model, subset, alpha=None, x=None, y=None, terms=None, norm_terms=None, title='SLISE Explanation', variables=None, order=None, decimals=3, fig=None)</code>","text":"<p>Plot the SLISE result with density distributions for the dataset and barplot for the model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>model</code> <code>ndarray</code> <p>Linear model.</p> required <code>subset</code> <code>ndarray</code> <p>Selected subset.</p> required <code>alpha</code> <code>Optional[ndarray]</code> <p>Scaled model. Defaults to None.</p> <code>None</code> <code>x</code> <code>Optional[ndarray]</code> <p>The explained item (if it is an explanation). Defaults to None.</p> <code>None</code> <code>y</code> <code>Optional[float]</code> <p>The explained outcome (if it is an explanation). Defaults to None.</p> <code>None</code> <code>terms</code> <code>Optional[ndarray]</code> <p>Term vector (unscaled x*alpha), if available. Defaults to None.</p> <code>None</code> <code>norm_terms</code> <code>Optional[ndarray]</code> <p>Term vector (scaled x*alpha), if available. Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Explanation\".</p> <code>'SLISE Explanation'</code> <code>order</code> <code>Union[None, int, Sequence[int]]</code> <p>Select variables (None: all, int: largest, selected). Defaults to all.</p> <code>None</code> <code>variables</code> <code>Optional[List[str]]</code> <p>Names for the (columns/) variables. Defaults to None.</p> <code>None</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing numbers. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Optional[Figure]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/plot.py</code> <pre><code>def plot_dist(\n    X: np.ndarray,\n    Y: np.ndarray,\n    model: np.ndarray,\n    subset: np.ndarray,\n    alpha: Optional[np.ndarray] = None,\n    x: Optional[np.ndarray] = None,\n    y: Optional[float] = None,\n    terms: Optional[np.ndarray] = None,\n    norm_terms: Optional[np.ndarray] = None,\n    title: str = \"SLISE Explanation\",\n    variables: Optional[List[str]] = None,\n    order: Union[None, int, Sequence[int]] = None,\n    decimals: int = 3,\n    fig: Optional[Figure] = None,\n):\n    \"\"\"Plot the SLISE result with density distributions for the dataset and barplot for the model.\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        model (np.ndarray): Linear model.\n        subset (np.ndarray): Selected subset.\n        alpha (Optional[np.ndarray]): Scaled model. Defaults to None.\n        x (Optional[np.ndarray], optional): The explained item (if it is an explanation). Defaults to None.\n        y (Optional[float], optional): The explained outcome (if it is an explanation). Defaults to None.\n        terms (Optional[np.ndarray], optional): Term vector (unscaled x*alpha), if available. Defaults to None.\n        norm_terms (Optional[np.ndarray], optional): Term vector (scaled x*alpha), if available. Defaults to None.\n        title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n        order (Union[None, int, Sequence[int]], optional): Select variables (None: all, int: largest, selected). Defaults to all.\n        variables (Optional[List[str]], optional): Names for the (columns/) variables. Defaults to None.\n        decimals (int, optional): Number of decimals when writing numbers. Defaults to 3.\n        fig (Optional[Figure], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    # Values and order\n    variables = fill_column_names(variables, X.shape[1], True)\n    if alpha is None:\n        noalpha = True\n        alpha = model\n    else:\n        noalpha = False\n    order_offset = 0\n    if len(model) == X.shape[1]:\n        model = np.concatenate((np.zeros(1, model.dtype), model))\n        alpha = np.concatenate((np.zeros(1, model.dtype), alpha))\n        order_offset = 1\n        variables[0] = \"\"\n    if order is None:\n        order = get_explanation_order(np.abs(alpha), True)\n    elif isinstance(order, int):\n        order = get_explanation_order(np.abs(alpha), True, max=order)\n    else:\n        order = [0] + [i + order_offset for i in order if i + order_offset != 0]\n    model = model[order]\n    alpha = alpha[order]\n    if terms is not None:\n        terms = terms[order]\n    if norm_terms is not None:\n        norm_terms = norm_terms[order]\n    variables = [variables[i] for i in order]\n    subsize = subset.mean()\n\n    # Figures:\n    if isinstance(fig, Figure):\n        plot = False\n        axs = fig.subplots(len(order), 2, squeeze=False)\n    else:\n        plot = True\n        fig, axs = plt.subplots(len(order), 2, squeeze=False)\n    fig.suptitle(title)\n\n    # Density plots\n\n    def fill_density(ax, X, x, n):\n        if np.var(X) == 0:\n            X = np.random.normal(X[0], 1e-8, len(X))\n        kde1 = gaussian_kde(X, 0.2)\n        if np.sum(subset) &gt; 1:\n            kde2 = gaussian_kde(X[subset], 0.2)\n        else:\n            kde2 = lambda x: x * 0  # noqa: E731\n        lim = extended_limits(X, 0.1, 100)\n        ax.plot(lim, kde1(lim), color=\"black\", label=\"Dataset\")\n        ax.plot(\n            lim,\n            kde2(lim) * subsize,\n            color=SLISE_PURPLE,\n            label=f\"Subset: {subsize * 100:.0f}%\",\n        )\n        if x is not None:\n            ax.relim()\n            ax.vlines(x, *ax.get_ylim(), color=SLISE_ORANGE, label=\"Explained Item\")\n        ax.set_yticks([])\n        ax.set_ylabel(\n            n, rotation=0, horizontalalignment=\"right\", verticalalignment=\"center\"\n        )\n\n    if x is None and y is None:\n        fill_density(axs[0, 0], Y, y, \"Response\")\n    else:\n        fill_density(axs[0, 0], Y, y, \"Prediction\")\n    axs[0, 0].legend()\n    axs[0, 0].set_title(\"Dataset Distribution\")\n    for i, k, n in zip(range(1, len(order)), order[1:], variables[1:]):\n        fill_density(axs[i, 0], X[:, k - 1], x[k - 1] if x is not None else None, n)\n\n    # Bar plots\n    def text(x, y, v):\n        if v != 0:\n            axbig.text(\n                x,\n                y,\n                f\"{v:.{decimals}f}\",\n                ha=\"center\",\n                va=\"center\",\n                bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"grey\", alpha=0.75),\n            )\n\n    gs = axs[0, 1].get_gridspec()\n    for ax in axs[:, 1]:\n        ax.remove()\n    axbig = fig.add_subplot(gs[:, 1])\n    if x is None or y is None:\n        axbig.set_title(\"Linear Model\")\n    else:\n        axbig.set_title(\"Explanation\")\n    ticks = np.arange(len(variables))\n    axbig.set_yticks(ticks)\n    axbig.set_yticklabels(variables)\n    axbig.set_ylim(bottom=ticks[0] - 0.45, top=ticks[-1] + 0.45)\n    axbig.invert_yaxis()\n    if terms is None and noalpha:\n        column_color = [SLISE_ORANGE if v &lt; 0 else SLISE_PURPLE for v in alpha]\n        axbig.barh(ticks, alpha, color=column_color)\n        for y, v in zip(ticks, model):\n            text(0, y, v)\n    elif terms is None and not noalpha:\n        axbig.barh(\n            ticks - 0.2,\n            model / np.max(np.abs(model)),\n            height=0.35,\n            color=SLISE_PURPLE,\n            label=\"Coefficients\",\n        )\n        axbig.barh(\n            ticks + 0.2,\n            alpha / np.max(np.abs(alpha)),\n            height=0.35,\n            color=SLISE_ORANGE,\n            label=\"Normalised\",\n        )\n        for y, a, m in zip(ticks, alpha, model):\n            text(0, y, m)\n            text(0, y, a)\n        axbig.set_xticks([])\n        axbig.legend()\n    elif norm_terms is None:\n        axbig.barh(\n            ticks[1:] - 0.2,\n            model[1:] / np.max(np.abs(model)),\n            height=0.35,\n            color=SLISE_PURPLE,\n            label=\"Linear Model\",\n        )\n        axbig.barh(\n            ticks[0],\n            model[0] / np.max(np.abs(model)),\n            height=0.35,\n            color=SLISE_PURPLE,\n        )\n        axbig.barh(\n            ticks[1:] + 0.2,\n            terms[1:] / np.max(np.abs(terms[1:])),\n            height=0.35,\n            color=SLISE_ORANGE,\n            label=\"Prediction Term\",\n        )\n        for y, a, m in zip(ticks, terms, model):\n            if y == ticks[0]:\n                text(0, y, m)\n                continue\n            text(0, y - 0.2, m)\n            text(0, y + 0.2, a)\n        axbig.set_xticks([])\n        axbig.legend()\n    else:\n        axbig.barh(\n            ticks[1:] - 0.33,\n            model[1:] / np.max(np.abs(model)),\n            height=0.2,\n            color=SLISE_PURPLE,\n            label=\"Linear Model\",\n        )\n        axbig.barh(\n            ticks[0] - 0.11,\n            model[0] / np.max(np.abs(model)),\n            height=0.2,\n            color=SLISE_PURPLE,\n        )\n        axbig.barh(\n            ticks[1:] - 0.11,\n            alpha[1:] / np.max(np.abs(alpha)),\n            height=0.2,\n            color=SLISE_DARKPURPLE,\n            label=\"Normalised Model\",\n        )\n        axbig.barh(\n            ticks[0] + 0.11,\n            alpha[0] / np.max(np.abs(alpha)),\n            height=0.2,\n            color=SLISE_DARKPURPLE,\n        )\n        axbig.barh(\n            ticks[1:] + 0.11,\n            terms[1:] / np.max(np.abs(terms[1:])),\n            height=0.2,\n            color=SLISE_ORANGE,\n            label=\"Prediction Term\",\n        )\n        axbig.barh(\n            ticks[1:] + 0.33,\n            norm_terms[1:] / np.max(np.abs(norm_terms[1:])),\n            height=0.2,\n            color=SLISE_DARKORANGE,\n            label=\"Normalised Term\",\n        )\n        for y, i1, i2, m1, m2 in zip(ticks, terms, norm_terms, model, alpha):\n            if y == ticks[0]:\n                text(0, y - 0.11, m1)\n                text(0, y + 0.11, m2)\n                continue\n            text(0, y - 0.33, m1)\n            text(0, y - 0.11, m2)\n            text(0, y + 0.11, i1)\n            text(0, y + 0.33, i2)\n        axbig.set_xticks([])\n        axbig.legend()\n    axbig.yaxis.tick_right()\n\n    # Meta:\n    fig.tight_layout()\n    if plot:\n        plt.show()\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.plot_image","title":"<code>plot_image(x, y, Y, model, width, height, saturated=True, title='SLISE Explanation', classes=None, decimals=3, fig=None)</code>","text":"<p>Plot an explanation for a black and white image (e.g. MNIST).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The explained item.</p> required <code>y</code> <code>float</code> <p>The explained outcome.</p> required <code>Y</code> <code>ndarray</code> <p>Dataset response vector (used for guessing prediction formatting).</p> required <code>model</code> <code>ndarray</code> <p>The approximating model.</p> required <code>width</code> <code>int</code> <p>The width of the image.</p> required <code>height</code> <code>int</code> <p>The height of the image.</p> required <code>saturated</code> <code>bool</code> <p>Should the explanation be more saturated. Defaults to True.</p> <code>True</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Explanation\".</p> <code>'SLISE Explanation'</code> <code>classes</code> <code>Union[List, str, None]</code> <p>List of class names (first the negative, then the positive), or a single (positive) class name. Defaults to None.</p> <code>None</code> <code>decimals</code> <code>int</code> <p>The number of decimals to write. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Optional[Figure]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/plot.py</code> <pre><code>def plot_image(\n    x: np.ndarray,\n    y: float,\n    Y: np.ndarray,\n    model: np.ndarray,\n    width: int,\n    height: int,\n    saturated: bool = True,\n    title: str = \"SLISE Explanation\",\n    classes: Union[List, str, None] = None,\n    decimals: int = 3,\n    fig: Optional[Figure] = None,\n):\n    \"\"\"Plot an explanation for a black and white image (e.g. MNIST).\n\n    Args:\n        x (np.ndarray): The explained item.\n        y (float): The explained outcome.\n        Y (np.ndarray): Dataset response vector (used for guessing prediction formatting).\n        model (np.ndarray): The approximating model.\n        width (int): The width of the image.\n        height (int): The height of the image.\n        saturated (bool, optional): Should the explanation be more saturated. Defaults to True.\n        title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n        classes (Union[List, str, None], optional): List of class names (first the negative, then the positive), or a single (positive) class name. Defaults to None.\n        decimals (int, optional): The number of decimals to write. Defaults to 3.\n        fig (Optional[Figure], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    # intercept = model[0]\n    model = model[1:]\n    model.shape = (width, height)\n    x.shape = (width, height)\n    if saturated:\n        model = sigmoid(model * (4 / np.max(np.abs(model))))\n    if fig is None:\n        fig, [ax1, ax2] = plt.subplots(1, 2)\n        plot = True\n    else:\n        [ax1, ax2] = fig.subplots(1, 2)\n        plot = False\n    fig.suptitle(title)\n    # Image\n    ax1.imshow(x, cmap=BW_COLORMAP)\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n    ax1.set_title(\"Explained Item\")\n    ax1.set_xlabel(fill_prediction_str(y, Y, classes, decimals))\n    # Explanation Image\n    ax2.imshow(\n        model,\n        interpolation=\"none\",\n        cmap=SLISE_COLORMAP,\n        norm=Normalize(vmin=-0.1, vmax=1.1),\n    )\n    ax2.contour(range(height), range(width), x, levels=1, colors=\"#00000033\")\n    ax2.set_xticks([])\n    ax2.set_yticks([])\n    ax2.set_title(\"Explanation\")\n    if classes is None:\n        classes = [\"Negative\", \"Positive\"]\n    elif isinstance(classes, str):\n        classes = [\"Not \" + classes, classes]\n    ax2.legend(\n        (Patch(facecolor=SLISE_ORANGE), Patch(facecolor=SLISE_PURPLE)),\n        classes[:2],\n        loc=\"upper center\",\n        bbox_to_anchor=(0.5, -0.01),\n        ncol=2,\n    )\n    fig.tight_layout()\n    if plot:\n        plt.show()\n</code></pre>"},{"location":"docs/slise.plot/#slise.plot.plot_dist_single","title":"<code>plot_dist_single(data, subset, item=None, title='Response Distribution', decimals=0, fig=None)</code>","text":"<p>Plot a density distributions for a single variable of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Variable vector.</p> required <code>subset</code> <code>ndarray</code> <p>Selected subset.</p> required <code>item</code> <code>Optional[ndarray]</code> <p>The explained item (if it is an explanation). Defaults to None.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"Response Distribution\".</p> <code>'Response Distribution'</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing the subset size. Defaults to 0.</p> <code>0</code> <code>fig</code> <code>Optional[Figure]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/plot.py</code> <pre><code>def plot_dist_single(\n    data: np.ndarray,\n    subset: np.ndarray,\n    item: Optional[float] = None,\n    title: str = \"Response Distribution\",\n    decimals: int = 0,\n    fig: Optional[Figure] = None,\n):\n    \"\"\"Plot a density distributions for a single variable of the dataset.\n\n    Args:\n        data (np.ndarray): Variable vector.\n        subset (np.ndarray): Selected subset.\n        item (Optional[np.ndarray], optional): The explained item (if it is an explanation). Defaults to None.\n        title (str, optional): Title of the plot. Defaults to \"Response Distribution\".\n        decimals (int, optional): Number of decimals when writing the subset size. Defaults to 0.\n        fig (Optional[Figure], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    subsize = subset.mean()\n    if isinstance(fig, Figure):\n        ax = fig.subplots(1, 1)\n        plot = False\n    else:\n        fig, ax = plt.subplots(1, 1)\n        plot = True\n    ax.set_title(title)\n    kde1 = gaussian_kde(data, 0.2)\n    kde2 = gaussian_kde(data[subset], 0.2)\n    lim = extended_limits(data, 0.1, 100)\n    ax.plot(lim, kde1(lim), color=\"black\", label=\"Dataset\")\n    ax.plot(\n        lim,\n        kde2(lim) * subsize,\n        color=SLISE_PURPLE,\n        label=f\"Subset: {subsize * 100:.{decimals}f}%\",\n    )\n    if item is not None:\n        ax.relim()\n        ax.vlines(item, *ax.get_ylim(), color=SLISE_ORANGE, label=\"Explained Item\")\n    ax.set_yticks([])\n    ax.legend()\n    if plot:\n        plt.show()\n</code></pre>"},{"location":"docs/slise.slise/","title":"slise.slise","text":""},{"location":"docs/slise.slise/#slise.slise","title":"<code>slise.slise</code>","text":"<p>This script contains the main SLISE functions, and classes.</p> <p>The library can both be used \"sk-learn\" style with <code>SliseRegression(...).fit(X, y)</code> and <code>SliseExplanation(...).explain(index)</code>, or in a more functional style with <code>regression(...)</code> and <code>explain(...)</code>.</p>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression","title":"<code>SliseRegression</code>","text":"<p>Class for holding the result from using SLISE for regression. Can also be used sklearn-style to do regression.</p> Source code in <code>slise/slise.py</code> <pre><code>class SliseRegression:\n    \"\"\"\n    Class for holding the result from using SLISE for regression.\n    Can also be used sklearn-style to do regression.\n    \"\"\"\n\n    def __init__(\n        self,\n        epsilon: float,\n        lambda1: float = 0,\n        lambda2: float = 0,\n        intercept: bool = True,\n        normalise: bool = False,\n        initialisation: Callable[\n            [np.ndarray, np.ndarray, float, Optional[np.ndarray]],\n            Tuple[np.ndarray, float],\n        ] = initialise_candidates,\n        beta_max: float = 20,\n        max_approx: float = 1.15,\n        max_iterations: int = 300,\n        debug: bool = False,\n        num_threads: int = 1,\n    ):\n        \"\"\"Use SLISE for robust regression.\n\n        In robust regression we fit regression models that can handle data that\n        contains outliers. SLISE accomplishes this by fitting a model such that\n        the largest possible subset of the data items have an error less than a\n        given value. All items with an error larger than that are considered\n        potential outliers and do not affect the resulting model.\n\n        This constructor prepares the parameters, call `fit` to fit a robust regression to a dataset.\n        It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.\n\n        Args:\n            epsilon (float): Error tolerance.\n            lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n            lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n            intercept (bool, optional): Add an intercept term. Defaults to True.\n            normalise (bool, optional): Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.\n            initialisation (Callable[ [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float] ], optional): Function that takes `(X, Y, epsilon, weight)` and gives an initial values for alpha and beta. Defaults to initialise_candidates.\n            beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n            max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n            max_iterations (int, optional): Maximum number of OWL-QN iterations. Defaults to 300.\n            debug (bool, optional): Print debug statements each graduated optimisation step. Defaults to False.\n            num_threads (int, optional): The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.\n        \"\"\"\n        assert epsilon &gt; 0.0, \"`epsilon` must be positive!\"\n        assert lambda1 &gt;= 0.0, \"`lambda1` must not be negative!\"\n        assert lambda2 &gt;= 0.0, \"`lambda2` must not be negative!\"\n        assert beta_max &gt; 0.0, \"`beta_max` must be positive!\"\n        assert max_approx &gt; 1.0, \"`max_approx` must be larger than 1.0!\"\n        assert max_iterations &gt; 0, \"`max_iterations` must be positive!\"\n        self.epsilon = epsilon\n        self.lambda1 = lambda1\n        self.lambda2 = lambda2\n        self.init_fn = initialisation\n        self.beta_max = beta_max\n        self.max_approx = max_approx\n        self.max_iterations = max_iterations\n        self.debug = debug\n        self._intercept = intercept\n        self._normalise = normalise\n        self._scale = None\n        self._X = None\n        self._Y = None\n        self._weight = None\n        self._alpha = None\n        self._coefficients = None\n        self.num_threads = num_threads\n        check_threading_layer()\n\n    def fit(\n        self,\n        X: np.ndarray,\n        Y: np.ndarray,\n        weight: Optional[np.ndarray] = None,\n        init: Union[None, np.ndarray, Tuple[np.ndarray, float]] = None,\n    ) -&gt; SliseRegression:\n        \"\"\"Robustly fit a linear regression to a dataset\n\n        Args:\n            X (np.ndarray): Data matrix.\n            Y (np.ndarray): Response vector.\n            weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n            init (Union[None, np.ndarray, Tuple[np.ndarray, float]], optional): Use this alpha (and beta) value instead of the initialisation function. Defaults to None.\n\n        Returns:\n            SliseRegression: `self` (containing the regression result).\n        \"\"\"\n        X = np.array(X)\n        Y = np.array(Y)\n        if len(X.shape) == 1:\n            X.shape = X.shape + (1,)\n        assert X.shape[0] == Y.shape[0], \"X and Y must have the same number of items!\"\n        if len(Y.shape) &gt; 1:\n            Y = Y.ravel()\n            assert X.shape[0] == Y.shape[0], \"Y cannot have multiple columns!\"\n        self._X = X\n        self._Y = Y\n        if weight is None:\n            self._weight = None\n        else:\n            self._weight = np.array(weight)\n            assert len(self._weight) == len(\n                self._Y\n            ), \"Y and weight must have the same number of items!\"\n            assert np.all(self._weight &gt;= 0.0), \"Weights must not be negative!\"\n        # Preprocessing\n        if self._normalise:\n            X, x_cols = remove_constant_columns(X)\n            if self._X.shape[1] == X.shape[1]:\n                x_cols = None\n            X, x_center, x_scale = normalise_robust(X)\n            Y, y_center, y_scale = normalise_robust(Y)\n            self._scale = DataScaling(x_center, x_scale, y_center, y_scale, x_cols)\n        if self._intercept:\n            X = add_intercept_column(X)\n        # Initialisation\n        threads = set_threads(self.num_threads)\n        try:\n            if init is None:\n                alpha, beta = self.init_fn(X, Y, self.epsilon, self._weight)\n            else:\n                alpha, beta = initialise_fixed(init, X, Y, self.epsilon, self._weight)\n            # Optimisation\n            alpha = graduated_optimisation(\n                alpha=alpha,\n                X=X,\n                Y=Y,\n                epsilon=self.epsilon,\n                beta=beta,\n                lambda1=self.lambda1,\n                lambda2=self.lambda2,\n                weight=self._weight,\n                beta_max=self.beta_max,\n                max_approx=self.max_approx,\n                max_iterations=self.max_iterations,\n                debug=self.debug,\n            )\n        finally:\n            set_threads(threads)\n        self._alpha = alpha\n        if self._normalise:\n            alpha2 = self._scale.unscale_model(alpha)\n            if not self._intercept:\n                if np.abs(alpha2[0]) &gt; 1e-8:\n                    warn(\n                        \"Intercept introduced due to scaling, consider setting intercept=True (or normalise=False)\",\n                        SliseWarning,\n                    )\n                    self._intercept = True\n                    self._alpha = np.concatenate(([0], alpha))\n                else:\n                    alpha2 = alpha2[1:]\n            self._coefficients = alpha2\n        else:\n            self._coefficients = alpha\n        return self\n\n    def get_params(self, normalised: bool = False) -&gt; np.ndarray:\n        \"\"\"Get the coefficients of the linear model.\n\n        Args:\n            normalised (bool, optional): If the data is normalised within SLISE, return a linear model ftting the normalised data. Defaults to False.\n\n        Returns:\n            np.ndarray: The coefficients of the linear model.\n        \"\"\"\n        warn(\"Use `coefficients` instead of `get_params()`.\", SliseWarning)\n        return self._alpha if normalised else self._coefficients\n\n    @property\n    def coefficients(self) -&gt; np.ndarray:\n        \"\"\"Get the coefficients of the linear model.\n\n        Returns:\n            np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).\n        \"\"\"\n        if self._coefficients is None:\n            warn(\"Fit the model before retrieving coefficients\", SliseWarning)\n        return self._coefficients\n\n    def normalised(self, all_columns: bool = True) -&gt; Optional[np.ndarray]:\n        \"\"\"Get coefficients for normalised data (if the data is normalised within SLISE).\n\n        Args:\n            all_columns (bool, optional): Add coefficients for constant columns. Defaults to True.\n\n        Returns:\n            Optional[np.ndarray]: The normalised coefficients or None.\n        \"\"\"\n        if self._alpha is None:\n            warn(\"Fit the model before retrieving coefficients\", SliseWarning)\n        if self._normalise:\n            if all_columns:\n                return add_constant_columns(self._alpha, self._scale.columns, True)\n            else:\n                return self._alpha\n        else:\n            return None\n\n    @property\n    def scaled_epsilon(self) -&gt; float:\n        \"\"\"Espilon fitting unnormalised data (if the data is normalised).\n\n        Returns:\n            float: Scaled epsilon.\n        \"\"\"\n        if self._normalise:\n            return self.epsilon * self._scale.y_scale\n        else:\n            return self.epsilon\n\n    def predict(self, X: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n        \"\"\"Use the fitted model to predict new responses.\n\n        Args:\n            X (Union[np.ndarray, None], optional): Data matrix to predict, or None for using the fitted dataset. Defaults to None.\n\n        Returns:\n            np.ndarray: Predicted response.\n        \"\"\"\n        if X is None:\n            return mat_mul_inter(self._X, self.coefficients)\n        else:\n            return mat_mul_inter(X, self.coefficients)\n\n    def score(\n        self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n    ) -&gt; float:\n        \"\"\"Calculate the loss. Lower is better and it should usually be negative (unless the regularisation is very (too?) strong).\n\n        Args:\n            X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n            Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n        Returns:\n            float: The loss.\n        \"\"\"\n        if self._alpha is None:\n            warn(\"Fit the model before calculating the score\", SliseWarning)\n        if X is None or Y is None:\n            X = self._X\n            Y = self._Y\n        if self._normalise:\n            X = self._scale.scale_x(X)\n            Y = self._scale.scale_y(Y)\n        return loss_sharp(\n            self._alpha, X, Y, self.epsilon, self.lambda1, self.lambda2, self._weight\n        )\n\n    loss = score\n    value = score\n\n    def subset(\n        self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get the subset (of non-outliers) used for the robust regression model.\n\n        Args:\n            X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n            Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n        Returns:\n            np.ndarray: The selected subset as a boolean mask.\n        \"\"\"\n        if X is None or Y is None:\n            X = self._X\n            Y = self._Y\n        Y2 = mat_mul_inter(X, self.coefficients)\n        return (Y2 - Y) ** 2 &lt; self.scaled_epsilon**2\n\n    def print(\n        self,\n        variables: Union[List[str], None] = None,\n        decimals: int = 3,\n        num_var: int = 10,\n    ):\n        \"\"\"Print the current robust regression result.\n\n        Args:\n            variables (Union[List[str], None], optional): Names of the variables/columns in X. Defaults to None.\n            num_var (int, optional): Exclude zero weights if there are too many variables. Defaults to 10.\n            decimals (int, optional): Precision to use for printing. Defaults to 3.\n        \"\"\"\n        print_slise(\n            self.coefficients,\n            self._intercept,\n            self.subset(),\n            self.score(),\n            self.scaled_epsilon,\n            variables,\n            \"SLISE Regression\",\n            decimals,\n            num_var,\n            alpha=self.normalised(),\n        )\n\n    def plot_2d(\n        self,\n        title: str = \"SLISE Regression\",\n        label_x: str = \"x\",\n        label_y: str = \"y\",\n        decimals: int = 3,\n        fig: Union[Figure, None] = None,\n    ) -&gt; SliseRegression:\n        \"\"\"Plot the regression in a 2D scatter plot with a line for the regression model.\n\n        Args:\n            title (str, optional): Title of the plot. Defaults to \"SLISE Regression\".\n            label_x (str, optional): X-axis label. Defaults to \"x\".\n            label_y (str, optional): Y-axis label. Defaults to \"y\".\n            decimals (int, optional): Number of decimals when writing numbers. Defaults to 3.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n\n        Raises:\n            SliseException: If the data has too many dimensions.\n        \"\"\"\n        plot_2d(\n            self._X,\n            self._Y,\n            self.coefficients,\n            self.scaled_epsilon,\n            None,\n            None,\n            False,\n            title,\n            label_x,\n            label_y,\n            decimals,\n            fig,\n        )\n\n    def plot_dist(\n        self,\n        title: str = \"SLISE Regression\",\n        variables: list = None,\n        order: Union[None, int, Sequence[int]] = None,\n        decimals: int = 3,\n        fig: Union[Figure, None] = None,\n    ) -&gt; SliseExplainer:\n        \"\"\"Plot the regression with density distributions for the dataset and a barplot for the model.\n\n        Args:\n            title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n            variables (list, optional): Names for the variables. Defaults to None.\n            order (Union[None, int, Sequence[int]], optional): Select variables (None: all, int: largest, selected). Defaults to all.\n            decimals (int, optional): Number of decimals to write. Defaults to 3.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n        \"\"\"\n        plot_dist(\n            X=self._X,\n            Y=self._Y,\n            model=self.coefficients,\n            subset=self.subset(),\n            alpha=self.normalised(),\n            x=None,\n            y=None,\n            terms=None,\n            norm_terms=None,\n            title=title,\n            variables=variables,\n            order=order,\n            decimals=decimals,\n            fig=fig,\n        )\n\n    def plot_subset(\n        self,\n        title: str = \"Response Distribution\",\n        decimals: int = 0,\n        fig: Union[Figure, None] = None,\n    ):\n        \"\"\"Plot a density distributions for response and the response of the subset\n\n        Args:\n            title (str, optional): Title of the plot. Defaults to \"Response Distribution\".\n            decimals (int, optional): Number of decimals when writing the subset size. Defaults to 0.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n        \"\"\"\n        plot_dist_single(self._Y, self.subset(), None, title, decimals, fig)\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.coefficients","title":"<code>coefficients: np.ndarray</code>  <code>property</code>","text":"<p>Get the coefficients of the linear model.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).</p>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.scaled_epsilon","title":"<code>scaled_epsilon: float</code>  <code>property</code>","text":"<p>Espilon fitting unnormalised data (if the data is normalised).</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Scaled epsilon.</p>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.__init__","title":"<code>__init__(epsilon, lambda1=0, lambda2=0, intercept=True, normalise=False, initialisation=initialise_candidates, beta_max=20, max_approx=1.15, max_iterations=300, debug=False, num_threads=1)</code>","text":"<p>Use SLISE for robust regression.</p> <p>In robust regression we fit regression models that can handle data that contains outliers. SLISE accomplishes this by fitting a model such that the largest possible subset of the data items have an error less than a given value. All items with an error larger than that are considered potential outliers and do not affect the resulting model.</p> <p>This constructor prepares the parameters, call <code>fit</code> to fit a robust regression to a dataset. It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.</p> <p>Parameters:</p> Name Type Description Default <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>lambda1</code> <code>float</code> <p>L1 regularisation strength. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>L2 regularisation strength. Defaults to 0.</p> <code>0</code> <code>intercept</code> <code>bool</code> <p>Add an intercept term. Defaults to True.</p> <code>True</code> <code>normalise</code> <code>bool</code> <p>Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.</p> <code>False</code> <code>initialisation</code> <code>Callable[[ndarray, ndarray, float, Optional[ndarray]], Tuple[ndarray, float]]</code> <p>Function that takes <code>(X, Y, epsilon, weight)</code> and gives an initial values for alpha and beta. Defaults to initialise_candidates.</p> <code>initialise_candidates</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of OWL-QN iterations. Defaults to 300.</p> <code>300</code> <code>debug</code> <code>bool</code> <p>Print debug statements each graduated optimisation step. Defaults to False.</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.</p> <code>1</code> Source code in <code>slise/slise.py</code> <pre><code>def __init__(\n    self,\n    epsilon: float,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    intercept: bool = True,\n    normalise: bool = False,\n    initialisation: Callable[\n        [np.ndarray, np.ndarray, float, Optional[np.ndarray]],\n        Tuple[np.ndarray, float],\n    ] = initialise_candidates,\n    beta_max: float = 20,\n    max_approx: float = 1.15,\n    max_iterations: int = 300,\n    debug: bool = False,\n    num_threads: int = 1,\n):\n    \"\"\"Use SLISE for robust regression.\n\n    In robust regression we fit regression models that can handle data that\n    contains outliers. SLISE accomplishes this by fitting a model such that\n    the largest possible subset of the data items have an error less than a\n    given value. All items with an error larger than that are considered\n    potential outliers and do not affect the resulting model.\n\n    This constructor prepares the parameters, call `fit` to fit a robust regression to a dataset.\n    It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.\n\n    Args:\n        epsilon (float): Error tolerance.\n        lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n        lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n        intercept (bool, optional): Add an intercept term. Defaults to True.\n        normalise (bool, optional): Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.\n        initialisation (Callable[ [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float] ], optional): Function that takes `(X, Y, epsilon, weight)` and gives an initial values for alpha and beta. Defaults to initialise_candidates.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        max_iterations (int, optional): Maximum number of OWL-QN iterations. Defaults to 300.\n        debug (bool, optional): Print debug statements each graduated optimisation step. Defaults to False.\n        num_threads (int, optional): The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.\n    \"\"\"\n    assert epsilon &gt; 0.0, \"`epsilon` must be positive!\"\n    assert lambda1 &gt;= 0.0, \"`lambda1` must not be negative!\"\n    assert lambda2 &gt;= 0.0, \"`lambda2` must not be negative!\"\n    assert beta_max &gt; 0.0, \"`beta_max` must be positive!\"\n    assert max_approx &gt; 1.0, \"`max_approx` must be larger than 1.0!\"\n    assert max_iterations &gt; 0, \"`max_iterations` must be positive!\"\n    self.epsilon = epsilon\n    self.lambda1 = lambda1\n    self.lambda2 = lambda2\n    self.init_fn = initialisation\n    self.beta_max = beta_max\n    self.max_approx = max_approx\n    self.max_iterations = max_iterations\n    self.debug = debug\n    self._intercept = intercept\n    self._normalise = normalise\n    self._scale = None\n    self._X = None\n    self._Y = None\n    self._weight = None\n    self._alpha = None\n    self._coefficients = None\n    self.num_threads = num_threads\n    check_threading_layer()\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.fit","title":"<code>fit(X, Y, weight=None, init=None)</code>","text":"<p>Robustly fit a linear regression to a dataset</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>init</code> <code>Union[None, ndarray, Tuple[ndarray, float]]</code> <p>Use this alpha (and beta) value instead of the initialisation function. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SliseRegression</code> <code>SliseRegression</code> <p><code>self</code> (containing the regression result).</p> Source code in <code>slise/slise.py</code> <pre><code>def fit(\n    self,\n    X: np.ndarray,\n    Y: np.ndarray,\n    weight: Optional[np.ndarray] = None,\n    init: Union[None, np.ndarray, Tuple[np.ndarray, float]] = None,\n) -&gt; SliseRegression:\n    \"\"\"Robustly fit a linear regression to a dataset\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        init (Union[None, np.ndarray, Tuple[np.ndarray, float]], optional): Use this alpha (and beta) value instead of the initialisation function. Defaults to None.\n\n    Returns:\n        SliseRegression: `self` (containing the regression result).\n    \"\"\"\n    X = np.array(X)\n    Y = np.array(Y)\n    if len(X.shape) == 1:\n        X.shape = X.shape + (1,)\n    assert X.shape[0] == Y.shape[0], \"X and Y must have the same number of items!\"\n    if len(Y.shape) &gt; 1:\n        Y = Y.ravel()\n        assert X.shape[0] == Y.shape[0], \"Y cannot have multiple columns!\"\n    self._X = X\n    self._Y = Y\n    if weight is None:\n        self._weight = None\n    else:\n        self._weight = np.array(weight)\n        assert len(self._weight) == len(\n            self._Y\n        ), \"Y and weight must have the same number of items!\"\n        assert np.all(self._weight &gt;= 0.0), \"Weights must not be negative!\"\n    # Preprocessing\n    if self._normalise:\n        X, x_cols = remove_constant_columns(X)\n        if self._X.shape[1] == X.shape[1]:\n            x_cols = None\n        X, x_center, x_scale = normalise_robust(X)\n        Y, y_center, y_scale = normalise_robust(Y)\n        self._scale = DataScaling(x_center, x_scale, y_center, y_scale, x_cols)\n    if self._intercept:\n        X = add_intercept_column(X)\n    # Initialisation\n    threads = set_threads(self.num_threads)\n    try:\n        if init is None:\n            alpha, beta = self.init_fn(X, Y, self.epsilon, self._weight)\n        else:\n            alpha, beta = initialise_fixed(init, X, Y, self.epsilon, self._weight)\n        # Optimisation\n        alpha = graduated_optimisation(\n            alpha=alpha,\n            X=X,\n            Y=Y,\n            epsilon=self.epsilon,\n            beta=beta,\n            lambda1=self.lambda1,\n            lambda2=self.lambda2,\n            weight=self._weight,\n            beta_max=self.beta_max,\n            max_approx=self.max_approx,\n            max_iterations=self.max_iterations,\n            debug=self.debug,\n        )\n    finally:\n        set_threads(threads)\n    self._alpha = alpha\n    if self._normalise:\n        alpha2 = self._scale.unscale_model(alpha)\n        if not self._intercept:\n            if np.abs(alpha2[0]) &gt; 1e-8:\n                warn(\n                    \"Intercept introduced due to scaling, consider setting intercept=True (or normalise=False)\",\n                    SliseWarning,\n                )\n                self._intercept = True\n                self._alpha = np.concatenate(([0], alpha))\n            else:\n                alpha2 = alpha2[1:]\n        self._coefficients = alpha2\n    else:\n        self._coefficients = alpha\n    return self\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.get_params","title":"<code>get_params(normalised=False)</code>","text":"<p>Get the coefficients of the linear model.</p> <p>Parameters:</p> Name Type Description Default <code>normalised</code> <code>bool</code> <p>If the data is normalised within SLISE, return a linear model ftting the normalised data. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The coefficients of the linear model.</p> Source code in <code>slise/slise.py</code> <pre><code>def get_params(self, normalised: bool = False) -&gt; np.ndarray:\n    \"\"\"Get the coefficients of the linear model.\n\n    Args:\n        normalised (bool, optional): If the data is normalised within SLISE, return a linear model ftting the normalised data. Defaults to False.\n\n    Returns:\n        np.ndarray: The coefficients of the linear model.\n    \"\"\"\n    warn(\"Use `coefficients` instead of `get_params()`.\", SliseWarning)\n    return self._alpha if normalised else self._coefficients\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.normalised","title":"<code>normalised(all_columns=True)</code>","text":"<p>Get coefficients for normalised data (if the data is normalised within SLISE).</p> <p>Parameters:</p> Name Type Description Default <code>all_columns</code> <code>bool</code> <p>Add coefficients for constant columns. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Optional[np.ndarray]: The normalised coefficients or None.</p> Source code in <code>slise/slise.py</code> <pre><code>def normalised(self, all_columns: bool = True) -&gt; Optional[np.ndarray]:\n    \"\"\"Get coefficients for normalised data (if the data is normalised within SLISE).\n\n    Args:\n        all_columns (bool, optional): Add coefficients for constant columns. Defaults to True.\n\n    Returns:\n        Optional[np.ndarray]: The normalised coefficients or None.\n    \"\"\"\n    if self._alpha is None:\n        warn(\"Fit the model before retrieving coefficients\", SliseWarning)\n    if self._normalise:\n        if all_columns:\n            return add_constant_columns(self._alpha, self._scale.columns, True)\n        else:\n            return self._alpha\n    else:\n        return None\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.predict","title":"<code>predict(X=None)</code>","text":"<p>Use the fitted model to predict new responses.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[ndarray, None]</code> <p>Data matrix to predict, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Predicted response.</p> Source code in <code>slise/slise.py</code> <pre><code>def predict(self, X: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n    \"\"\"Use the fitted model to predict new responses.\n\n    Args:\n        X (Union[np.ndarray, None], optional): Data matrix to predict, or None for using the fitted dataset. Defaults to None.\n\n    Returns:\n        np.ndarray: Predicted response.\n    \"\"\"\n    if X is None:\n        return mat_mul_inter(self._X, self.coefficients)\n    else:\n        return mat_mul_inter(X, self.coefficients)\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.score","title":"<code>score(X=None, Y=None)</code>","text":"<p>Calculate the loss. Lower is better and it should usually be negative (unless the regularisation is very (too?) strong).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[ndarray, None]</code> <p>Data matrix, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <code>Y</code> <code>Union[ndarray, None]</code> <p>Response vector, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The loss.</p> Source code in <code>slise/slise.py</code> <pre><code>def score(\n    self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n) -&gt; float:\n    \"\"\"Calculate the loss. Lower is better and it should usually be negative (unless the regularisation is very (too?) strong).\n\n    Args:\n        X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n        Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n    Returns:\n        float: The loss.\n    \"\"\"\n    if self._alpha is None:\n        warn(\"Fit the model before calculating the score\", SliseWarning)\n    if X is None or Y is None:\n        X = self._X\n        Y = self._Y\n    if self._normalise:\n        X = self._scale.scale_x(X)\n        Y = self._scale.scale_y(Y)\n    return loss_sharp(\n        self._alpha, X, Y, self.epsilon, self.lambda1, self.lambda2, self._weight\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.subset","title":"<code>subset(X=None, Y=None)</code>","text":"<p>Get the subset (of non-outliers) used for the robust regression model.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[ndarray, None]</code> <p>Data matrix, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <code>Y</code> <code>Union[ndarray, None]</code> <p>Response vector, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The selected subset as a boolean mask.</p> Source code in <code>slise/slise.py</code> <pre><code>def subset(\n    self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n) -&gt; np.ndarray:\n    \"\"\"Get the subset (of non-outliers) used for the robust regression model.\n\n    Args:\n        X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n        Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n    Returns:\n        np.ndarray: The selected subset as a boolean mask.\n    \"\"\"\n    if X is None or Y is None:\n        X = self._X\n        Y = self._Y\n    Y2 = mat_mul_inter(X, self.coefficients)\n    return (Y2 - Y) ** 2 &lt; self.scaled_epsilon**2\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.print","title":"<code>print(variables=None, decimals=3, num_var=10)</code>","text":"<p>Print the current robust regression result.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>Union[List[str], None]</code> <p>Names of the variables/columns in X. Defaults to None.</p> <code>None</code> <code>num_var</code> <code>int</code> <p>Exclude zero weights if there are too many variables. Defaults to 10.</p> <code>10</code> <code>decimals</code> <code>int</code> <p>Precision to use for printing. Defaults to 3.</p> <code>3</code> Source code in <code>slise/slise.py</code> <pre><code>def print(\n    self,\n    variables: Union[List[str], None] = None,\n    decimals: int = 3,\n    num_var: int = 10,\n):\n    \"\"\"Print the current robust regression result.\n\n    Args:\n        variables (Union[List[str], None], optional): Names of the variables/columns in X. Defaults to None.\n        num_var (int, optional): Exclude zero weights if there are too many variables. Defaults to 10.\n        decimals (int, optional): Precision to use for printing. Defaults to 3.\n    \"\"\"\n    print_slise(\n        self.coefficients,\n        self._intercept,\n        self.subset(),\n        self.score(),\n        self.scaled_epsilon,\n        variables,\n        \"SLISE Regression\",\n        decimals,\n        num_var,\n        alpha=self.normalised(),\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.plot_2d","title":"<code>plot_2d(title='SLISE Regression', label_x='x', label_y='y', decimals=3, fig=None)</code>","text":"<p>Plot the regression in a 2D scatter plot with a line for the regression model.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Regression\".</p> <code>'SLISE Regression'</code> <code>label_x</code> <code>str</code> <p>X-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>label_y</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing numbers. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>SliseException</code> <p>If the data has too many dimensions.</p> Source code in <code>slise/slise.py</code> <pre><code>def plot_2d(\n    self,\n    title: str = \"SLISE Regression\",\n    label_x: str = \"x\",\n    label_y: str = \"y\",\n    decimals: int = 3,\n    fig: Union[Figure, None] = None,\n) -&gt; SliseRegression:\n    \"\"\"Plot the regression in a 2D scatter plot with a line for the regression model.\n\n    Args:\n        title (str, optional): Title of the plot. Defaults to \"SLISE Regression\".\n        label_x (str, optional): X-axis label. Defaults to \"x\".\n        label_y (str, optional): Y-axis label. Defaults to \"y\".\n        decimals (int, optional): Number of decimals when writing numbers. Defaults to 3.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n\n    Raises:\n        SliseException: If the data has too many dimensions.\n    \"\"\"\n    plot_2d(\n        self._X,\n        self._Y,\n        self.coefficients,\n        self.scaled_epsilon,\n        None,\n        None,\n        False,\n        title,\n        label_x,\n        label_y,\n        decimals,\n        fig,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.plot_dist","title":"<code>plot_dist(title='SLISE Regression', variables=None, order=None, decimals=3, fig=None)</code>","text":"<p>Plot the regression with density distributions for the dataset and a barplot for the model.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Explanation\".</p> <code>'SLISE Regression'</code> <code>variables</code> <code>list</code> <p>Names for the variables. Defaults to None.</p> <code>None</code> <code>order</code> <code>Union[None, int, Sequence[int]]</code> <p>Select variables (None: all, int: largest, selected). Defaults to all.</p> <code>None</code> <code>decimals</code> <code>int</code> <p>Number of decimals to write. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/slise.py</code> <pre><code>def plot_dist(\n    self,\n    title: str = \"SLISE Regression\",\n    variables: list = None,\n    order: Union[None, int, Sequence[int]] = None,\n    decimals: int = 3,\n    fig: Union[Figure, None] = None,\n) -&gt; SliseExplainer:\n    \"\"\"Plot the regression with density distributions for the dataset and a barplot for the model.\n\n    Args:\n        title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n        variables (list, optional): Names for the variables. Defaults to None.\n        order (Union[None, int, Sequence[int]], optional): Select variables (None: all, int: largest, selected). Defaults to all.\n        decimals (int, optional): Number of decimals to write. Defaults to 3.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    plot_dist(\n        X=self._X,\n        Y=self._Y,\n        model=self.coefficients,\n        subset=self.subset(),\n        alpha=self.normalised(),\n        x=None,\n        y=None,\n        terms=None,\n        norm_terms=None,\n        title=title,\n        variables=variables,\n        order=order,\n        decimals=decimals,\n        fig=fig,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseRegression.plot_subset","title":"<code>plot_subset(title='Response Distribution', decimals=0, fig=None)</code>","text":"<p>Plot a density distributions for response and the response of the subset</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"Response Distribution\".</p> <code>'Response Distribution'</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing the subset size. Defaults to 0.</p> <code>0</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/slise.py</code> <pre><code>def plot_subset(\n    self,\n    title: str = \"Response Distribution\",\n    decimals: int = 0,\n    fig: Union[Figure, None] = None,\n):\n    \"\"\"Plot a density distributions for response and the response of the subset\n\n    Args:\n        title (str, optional): Title of the plot. Defaults to \"Response Distribution\".\n        decimals (int, optional): Number of decimals when writing the subset size. Defaults to 0.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    plot_dist_single(self._Y, self.subset(), None, title, decimals, fig)\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer","title":"<code>SliseExplainer</code>","text":"<p>Class for holding the result from using SLISE as an explainer. Can also be used sklearn-style to create explanations.</p> Source code in <code>slise/slise.py</code> <pre><code>class SliseExplainer:\n    \"\"\"\n    Class for holding the result from using SLISE as an explainer.\n    Can also be used sklearn-style to create explanations.\n    \"\"\"\n\n    def __init__(\n        self,\n        X: np.ndarray,\n        Y: np.ndarray,\n        epsilon: float,\n        lambda1: float = 0,\n        lambda2: float = 0,\n        logit: bool = False,\n        normalise: bool = False,\n        initialisation: Callable[\n            [np.ndarray, np.ndarray, float, Optional[np.ndarray]],\n            Tuple[np.ndarray, float],\n        ] = initialise_candidates,\n        beta_max: float = 20,\n        max_approx: float = 1.15,\n        max_iterations: int = 300,\n        debug: bool = False,\n        num_threads: int = 1,\n    ):\n        \"\"\"Use SLISE for explaining outcomes from black box models.\n\n        SLISE can also be used to provide local model-agnostic explanations for\n        outcomes from black box models. To do this we replace the ground truth\n        response vector with the predictions from the complex model.\n        Furthermore, we force the model to fit a selected item (making the\n        explanation local). This gives us a local approximation of the complex\n        model with a simpler linear model. In contrast to other methods SLISE\n        creates explanations using real data (not some discretised and randomly\n        sampled data) so we can be sure that all inputs are valid (i.e. in the\n        correct data manifold, and follows the constraints used to generate the\n        data, e.g., the laws of physics).\n\n        This prepares the dataset used for the explanations, call `explain` on this object to explain outcomes.\n        It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.\n\n        Args:\n            X (np.ndarray): Data matrix.\n            Y (np.ndarray): Vector of predictions.\n            epsilon (float): Error tolerance.\n            lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n            lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n            logit (bool, optional): Do a logit transformation on the Y vector, this is recommended opnly if Y consists of probabilities. Defaults to False.\n            normalise (bool, optional): Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.\n            initialisation (Callable[ [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float] ], optional): Function that takes `(X, Y, epsilon, weight)` and gives an initial values for alpha and beta. Defaults to initialise_candidates.\n            beta_max (float, optional): The final sigmoid steepness. Defaults to 20.\n            max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n            max_iterations (int, optional): Maximum number of OWL-QN iterations. Defaults to 300.\n            debug (bool, optional): Print debug statements each graduated optimisation step. Defaults to False.\n            num_threads (int, optional): The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.\n        \"\"\"\n        assert epsilon &gt; 0.0, \"`epsilon` must be positive!\"\n        assert lambda1 &gt;= 0.0, \"`lambda1` must not be negative!\"\n        assert lambda2 &gt;= 0.0, \"`lambda2` must not be negative!\"\n        assert beta_max &gt; 0.0, \"`beta_max` must be positive!\"\n        assert max_approx &gt; 1.0, \"`max_approx` must be larger than 1.0!\"\n        assert max_iterations &gt; 0, \"`max_iterations` must be positive!\"\n        self.epsilon = epsilon\n        self.lambda1 = lambda1\n        self.lambda2 = lambda2\n        self.init_fn = initialisation\n        self.beta_max = beta_max\n        self.max_approx = max_approx\n        self.max_iterations = max_iterations\n        self.debug = debug\n        X = np.array(X)\n        Y = np.array(Y)\n        if len(X.shape) == 1:\n            X.shape = X.shape + (1,)\n        assert X.shape[0] == Y.shape[0], \"X and Y must have the same number of items\"\n        if len(Y.shape) &gt; 1:\n            Y = Y.ravel()\n            assert X.shape[0] == Y.shape[0], \"Y cannot have multiple columns!\"\n        self._logit = logit\n        self._normalise = normalise\n        self._X = X\n        self._Y = Y\n        self._x = None\n        self._y = None\n        self._weight = None\n        self._alpha = None\n        self._coefficients = None\n        # Preprocess data\n        if logit:\n            Y = limited_logit(Y)\n        if normalise:\n            X2, x_cols = remove_constant_columns(X)\n            if X.shape[1] == X2.shape[1]:\n                x_cols = None\n            X, x_center, x_scale = normalise_robust(X2)\n            if logit:\n                (y_center, y_scale) = (0, 1)\n            else:\n                Y, y_center, y_scale = normalise_robust(Y)\n            self._scale = DataScaling(x_center, x_scale, y_center, y_scale, x_cols)\n        else:\n            self._scale = None\n        self._X2 = X\n        self._Y2 = Y\n        self.num_threads = num_threads\n        check_threading_layer()\n\n    def explain(\n        self,\n        x: Union[np.ndarray, int],\n        y: Union[float, None] = None,\n        weight: Optional[np.ndarray] = None,\n        init: Union[None, np.ndarray, Tuple[np.ndarray, float]] = None,\n    ) -&gt; SliseExplainer:\n        \"\"\"Explain an outcome from a black box model\n\n        Args:\n            x (Union[np.ndarray, int]): Data item to explain, or an index to get the item from self.X\n            y (Union[float, None], optional): Prediction to explain. If x is an index then this should be None (y is taken from self.Y). Defaults to None.\n            weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n            init (Union[None, np.ndarray, Tuple[np.ndarray, float]], optional): Use this alpha (and beta) value instead of the initialisation function. Defaults to None.\n\n        Returns:\n            SliseExplainer: `self` (containing the explanation).\n        \"\"\"\n        if weight is None:\n            self._weight = None\n        else:\n            self._weight = np.array(weight)\n            assert len(self._weight) == len(\n                self._Y\n            ), \"Y and weight must have the same number of items!\"\n            assert np.all(self._weight &gt;= 0.0), \"Weights must not be negative!\"\n        if y is None:\n            assert isinstance(x, int) and (\n                0 &lt;= x &lt; self._Y.shape[0]\n            ), \"If y is None then x must be an integer index [0, len(Y)[\"\n            self._y = self._Y[x]\n            self._x = self._X[x, :]\n            y = self._Y2[x]\n            x = self._X2[x, :]\n        else:\n            x = np.atleast_1d(np.array(x))\n            self._x = x\n            self._y = y\n            if self._logit:\n                y = limited_logit(y)\n            if self._normalise:\n                x = self._scale.scale_x(x)\n                y = self._scale.scale_y(y)\n        X = self._X2 - x[None, :]\n        Y = self._Y2 - y\n        threads = set_threads(self.num_threads)\n        try:\n            if init is None:\n                alpha, beta = self.init_fn(X, Y, self.epsilon, self._weight)\n            else:\n                alpha, beta = initialise_fixed(init, X, Y, self.epsilon, self._weight)\n            alpha = graduated_optimisation(\n                alpha=alpha,\n                X=X,\n                Y=Y,\n                epsilon=self.epsilon,\n                beta=beta,\n                lambda1=self.lambda1,\n                lambda2=self.lambda2,\n                weight=self._weight,\n                beta_max=self.beta_max,\n                max_approx=self.max_approx,\n                max_iterations=self.max_iterations,\n                debug=self.debug,\n            )\n        finally:\n            set_threads(threads)\n        alpha = np.concatenate(\n            (y - np.sum(alpha * x, dtype=x.dtype, keepdims=True), alpha)\n        )\n        self._alpha = alpha\n        if self._normalise:\n            y = self._y\n            if self._logit:\n                y = limited_logit(y)\n            alpha2 = self._scale.unscale_model(alpha)\n            alpha2[0] = y - np.sum(self._x * alpha2[1:])\n            self._coefficients = alpha2\n        else:\n            self._coefficients = alpha\n        return self\n\n    def get_params(self, normalised: bool = False) -&gt; np.ndarray:\n        \"\"\"Get the explanation as the coefficients of a linear model (approximating the black box model).\n\n        Args:\n            normalised (bool, optional): If the data is normalised within SLISE, return a linear model fitting the normalised data. Defaults to False.\n\n        Returns:\n            np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).\n        \"\"\"\n        warn(\"Use `coefficients` instead of `get_params().\", SliseWarning)\n        return self._alpha if normalised else self._coefficients\n\n    @property\n    def coefficients(self) -&gt; np.ndarray:\n        \"\"\"Get the explanation as the coefficients of a linear model (approximating the black box model).\n\n        Returns:\n            np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).\n        \"\"\"\n        if self._coefficients is None:\n            warn(\"Fit an explanation before retrieving coefficients\", SliseWarning)\n        return self._coefficients\n\n    def normalised(self, all_columns: bool = True) -&gt; Optional[np.ndarray]:\n        \"\"\"Get coefficients for normalised data (if the data is normalised within SLISE).\n\n        Args:\n            all_columns (bool, optional): Add coefficients for constant columns. Defaults to True.\n\n        Returns:\n            Optional[np.ndarray]: The normalised coefficients or None.\n        \"\"\"\n        if self._alpha is None:\n            warn(\"Fit an explanation before retrieving coefficients\", SliseWarning)\n        if self._normalise:\n            if all_columns:\n                return add_constant_columns(self._alpha, self._scale.columns, True)\n            else:\n                return self._alpha\n        else:\n            return None\n\n    @property\n    def scaled_epsilon(self) -&gt; float:\n        \"\"\"Espilon fitting unnormalised data (if the data is normalised).\n\n        Returns:\n            float: Scaled epsilon.\n        \"\"\"\n        if self._normalise:\n            return self.epsilon * self._scale.y_scale\n        else:\n            return self.epsilon\n\n    def predict(self, X: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n        \"\"\"Use the approximating linear model to predict new outcomes.\n\n        Args:\n            X (Union[np.ndarray, None], optional): Sata matrix to predict, or None for using the fitted dataset. Defaults to None.\n\n        Returns:\n            np.ndarray: Prediction vector.\n        \"\"\"\n        if X is None:\n            Y = mat_mul_inter(self._X, self.coefficients)\n        else:\n            Y = mat_mul_inter(X, self.coefficients)\n        if self._logit:\n            Y = sigmoid(Y)\n        return Y\n\n    def score(\n        self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n    ) -&gt; float:\n        \"\"\"Calculate the loss. Lower is better and it should usually be negative (unless the regularisation is very (/too?) strong).\n\n        Args:\n            X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n            Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n        Returns:\n            float: The loss.\n        \"\"\"\n        if self._alpha is None:\n            warn(\"Fit an explanation before calculating the score\", SliseWarning)\n        x = self._x\n        y = self._y\n        if self._logit:\n            y = limited_logit(y)\n        if self._normalise:\n            x = self._scale.scale_x(x)\n            y = self._scale.scale_y(y)\n        if X is None or Y is None:\n            X = self._X2\n            Y = self._Y2\n        else:\n            if self._logit:\n                Y = limited_logit(Y)\n            if self._normalise:\n                X = self._scale.scale_x(X)\n                Y = self._scale.scale_y(Y)\n        X = X - x[None, :]\n        Y = Y - y\n        return loss_sharp(\n            self._alpha[1:],\n            X,\n            Y,\n            self.epsilon,\n            self.lambda1,\n            self.lambda2,\n            self._weight,\n        )\n\n    loss = score\n    value = score\n\n    def subset(\n        self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get the subset / neighbourhood used for the approximation (explanation).\n\n        Args:\n            X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n            Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n        Returns:\n            np.ndarray: The subset as a boolean mask.\n        \"\"\"\n        if X is None or Y is None:\n            X = self._X\n            Y = self._Y\n        if self._logit:\n            Y = limited_logit(Y)\n        res = mat_mul_inter(X, self.coefficients) - Y\n        return res**2 &lt; self.scaled_epsilon**2\n\n    def get_terms(\n        self, normalised: bool = False, x: Union[None, np.ndarray] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Get the \"terms\" of different variables on the outcome.\n            The terms are the (normalised) coefficients times the (normalised) values.\n\n        Args:\n            normalised (bool, optional): Return the normalised terms (if normalisation is used). Defaults to False.\n            x (Union[None, np.ndarray], optional): The item to calculate the terms for (uses the explained item if None). Defaults to None.\n\n        Returns:\n            np.ndarray: The terms vector.\n        \"\"\"\n        if x is None:\n            x = self._x\n        if normalised and self._normalise:\n            x = add_constant_columns(self._scale.scale_x(x), self._scale.columns, False)\n            return add_intercept_column(x) * self.coefficients\n        else:\n            return add_intercept_column(x) * self.coefficients\n\n    get_impact = get_terms\n\n    def print(\n        self,\n        variables: Union[List[str], None] = None,\n        classes: Union[List[str], None] = None,\n        num_var: int = 10,\n        decimals: int = 3,\n    ):\n        \"\"\"Print the current explanation.\n\n        Args:\n            variables (Union[List[str], None], optional): Names of the (columns/) variables. Defaults to None.\n            classes (Union[List[str], None], optional): Names of the classes, if explaining a classifier. Defaults to None.\n            num_var (int, optional): Exclude zero weights if there are too many variables. Defaults to 10.\n            decimals (int, optional): Precision to use for printing. Defaults to 3.\n        \"\"\"\n        print_slise(\n            self.coefficients,\n            True,\n            self.subset(),\n            self.score(),\n            self.scaled_epsilon,\n            variables,\n            \"SLISE Explanation\",\n            decimals,\n            num_var,\n            unscaled=self._x,\n            unscaled_y=self._y,\n            terms=self.get_terms(False),\n            scaled=None if self._scale is None else self._scale.scale_x(self._x, False),\n            alpha=self.normalised(),\n            scaled_terms=None if self._scale is None else self.get_terms(True),\n            classes=classes,\n            unscaled_preds=self._Y,\n            logit=self._logit,\n        )\n\n    def plot_2d(\n        self,\n        title: str = \"SLISE Explanation\",\n        label_x: str = \"x\",\n        label_y: str = \"y\",\n        decimals: int = 3,\n        fig: Union[Figure, None] = None,\n    ) -&gt; SliseRegression:\n        \"\"\"Plot the explanation in a 2D scatter plot (where the explained item is marked) with a line for the approximating model.\n\n        Args:\n            title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n            label_x (str, optional): x-axis label. Defaults to \"x\".\n            label_y (str, optional): Y-axis label. Defaults to \"y\".\n            decimals (int, optional): Number of decimals when writing numbers. Defaults to 3.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n\n        Raises:\n            SliseException: If the data has too many dimensions.\n        \"\"\"\n        plot_2d(\n            self._X,\n            self._Y,\n            self.coefficients,\n            self.scaled_epsilon,\n            self._x,\n            self._y,\n            self._logit,\n            title,\n            label_x,\n            label_y,\n            decimals,\n            fig,\n        )\n\n    def plot_image(\n        self,\n        width: int,\n        height: int,\n        saturated: bool = True,\n        title: str = \"SLISE Explanation\",\n        classes: Union[List, str, None] = None,\n        decimals: int = 3,\n        fig: Union[Figure, None] = None,\n    ) -&gt; SliseExplainer:\n        \"\"\"Plot the current explanation for a black and white image (e.g. MNIST).\n\n        Args:\n            width (int): Width of the image.\n            height (int): Height of the image.\n            saturated (bool, optional): Should the explanation be more saturated. Defaults to True.\n            title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n            classes (Union[List, str, None], optional): List of class names (first the negative, then the positive), or a single (positive) class name. Defaults to None.\n            decimals (int, optional): Number of decimals to write. Defaults to 3.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n        \"\"\"\n        plot_image(\n            self._x,\n            self._y,\n            self._Y,\n            self.coefficients,\n            width,\n            height,\n            saturated,\n            title,\n            classes,\n            decimals,\n            fig,\n        )\n\n    def plot_dist(\n        self,\n        title: str = \"SLISE Explanation\",\n        variables: list = None,\n        order: Union[None, int, Sequence[int]] = None,\n        decimals: int = 3,\n        fig: Union[Figure, None] = None,\n    ) -&gt; SliseExplainer:\n        \"\"\"Plot the current explanation with density distributions for the dataset and a barplot for the model.\n\n        The barplot contains both the approximating linear model (where the weights can be loosely interpreted as the importance of the different variables and their sign) and the \"terms\", which is the (scaled) model time the (scaled) item values.\n        The terms demonstrates how the explained item interacts with the approximating linear model, since a negative weight times a negative value actually supports a positive prediction.\n\n        Args:\n            title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n            variables (list, optional): Names for the variables. Defaults to None.\n            order (Union[None, int, Sequence[int]], optional): Select variables (None: all, int: largest, selected). Defaults to all.\n            decimals (int, optional): Number of decimals to write. Defaults to 3.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n        \"\"\"\n        plot_dist(\n            X=self._X,\n            Y=self._Y,\n            model=self.coefficients,\n            subset=self.subset(),\n            alpha=self.normalised(),\n            x=self._x,\n            y=self._y,\n            terms=self.get_terms(False),\n            norm_terms=self.get_terms(True) if self._normalise else None,\n            title=title,\n            variables=variables,\n            order=order,\n            decimals=decimals,\n            fig=fig,\n        )\n\n    def plot_subset(\n        self,\n        title: str = \"Prediction Distribution\",\n        decimals: int = 0,\n        fig: Union[Figure, None] = None,\n    ):\n        \"\"\"Plot a density distributions for predictions and the predictions of the subset\n\n        Args:\n            title (str, optional): Title of the plot. Defaults to \"Prediction Distribution\".\n            decimals (int, optional): Number of decimals when writing the subset size. Defaults to 0.\n            fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n        \"\"\"\n        plot_dist_single(self._Y, self.subset(), self._y, title, decimals, fig)\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.coefficients","title":"<code>coefficients: np.ndarray</code>  <code>property</code>","text":"<p>Get the explanation as the coefficients of a linear model (approximating the black box model).</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).</p>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.scaled_epsilon","title":"<code>scaled_epsilon: float</code>  <code>property</code>","text":"<p>Espilon fitting unnormalised data (if the data is normalised).</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Scaled epsilon.</p>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.__init__","title":"<code>__init__(X, Y, epsilon, lambda1=0, lambda2=0, logit=False, normalise=False, initialisation=initialise_candidates, beta_max=20, max_approx=1.15, max_iterations=300, debug=False, num_threads=1)</code>","text":"<p>Use SLISE for explaining outcomes from black box models.</p> <p>SLISE can also be used to provide local model-agnostic explanations for outcomes from black box models. To do this we replace the ground truth response vector with the predictions from the complex model. Furthermore, we force the model to fit a selected item (making the explanation local). This gives us a local approximation of the complex model with a simpler linear model. In contrast to other methods SLISE creates explanations using real data (not some discretised and randomly sampled data) so we can be sure that all inputs are valid (i.e. in the correct data manifold, and follows the constraints used to generate the data, e.g., the laws of physics).</p> <p>This prepares the dataset used for the explanations, call <code>explain</code> on this object to explain outcomes. It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Vector of predictions.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>lambda1</code> <code>float</code> <p>L1 regularisation strength. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>L2 regularisation strength. Defaults to 0.</p> <code>0</code> <code>logit</code> <code>bool</code> <p>Do a logit transformation on the Y vector, this is recommended opnly if Y consists of probabilities. Defaults to False.</p> <code>False</code> <code>normalise</code> <code>bool</code> <p>Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.</p> <code>False</code> <code>initialisation</code> <code>Callable[[ndarray, ndarray, float, Optional[ndarray]], Tuple[ndarray, float]]</code> <p>Function that takes <code>(X, Y, epsilon, weight)</code> and gives an initial values for alpha and beta. Defaults to initialise_candidates.</p> <code>initialise_candidates</code> <code>beta_max</code> <code>float</code> <p>The final sigmoid steepness. Defaults to 20.</p> <code>20</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of OWL-QN iterations. Defaults to 300.</p> <code>300</code> <code>debug</code> <code>bool</code> <p>Print debug statements each graduated optimisation step. Defaults to False.</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.</p> <code>1</code> Source code in <code>slise/slise.py</code> <pre><code>def __init__(\n    self,\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    logit: bool = False,\n    normalise: bool = False,\n    initialisation: Callable[\n        [np.ndarray, np.ndarray, float, Optional[np.ndarray]],\n        Tuple[np.ndarray, float],\n    ] = initialise_candidates,\n    beta_max: float = 20,\n    max_approx: float = 1.15,\n    max_iterations: int = 300,\n    debug: bool = False,\n    num_threads: int = 1,\n):\n    \"\"\"Use SLISE for explaining outcomes from black box models.\n\n    SLISE can also be used to provide local model-agnostic explanations for\n    outcomes from black box models. To do this we replace the ground truth\n    response vector with the predictions from the complex model.\n    Furthermore, we force the model to fit a selected item (making the\n    explanation local). This gives us a local approximation of the complex\n    model with a simpler linear model. In contrast to other methods SLISE\n    creates explanations using real data (not some discretised and randomly\n    sampled data) so we can be sure that all inputs are valid (i.e. in the\n    correct data manifold, and follows the constraints used to generate the\n    data, e.g., the laws of physics).\n\n    This prepares the dataset used for the explanations, call `explain` on this object to explain outcomes.\n    It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Vector of predictions.\n        epsilon (float): Error tolerance.\n        lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n        lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n        logit (bool, optional): Do a logit transformation on the Y vector, this is recommended opnly if Y consists of probabilities. Defaults to False.\n        normalise (bool, optional): Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.\n        initialisation (Callable[ [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float] ], optional): Function that takes `(X, Y, epsilon, weight)` and gives an initial values for alpha and beta. Defaults to initialise_candidates.\n        beta_max (float, optional): The final sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        max_iterations (int, optional): Maximum number of OWL-QN iterations. Defaults to 300.\n        debug (bool, optional): Print debug statements each graduated optimisation step. Defaults to False.\n        num_threads (int, optional): The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.\n    \"\"\"\n    assert epsilon &gt; 0.0, \"`epsilon` must be positive!\"\n    assert lambda1 &gt;= 0.0, \"`lambda1` must not be negative!\"\n    assert lambda2 &gt;= 0.0, \"`lambda2` must not be negative!\"\n    assert beta_max &gt; 0.0, \"`beta_max` must be positive!\"\n    assert max_approx &gt; 1.0, \"`max_approx` must be larger than 1.0!\"\n    assert max_iterations &gt; 0, \"`max_iterations` must be positive!\"\n    self.epsilon = epsilon\n    self.lambda1 = lambda1\n    self.lambda2 = lambda2\n    self.init_fn = initialisation\n    self.beta_max = beta_max\n    self.max_approx = max_approx\n    self.max_iterations = max_iterations\n    self.debug = debug\n    X = np.array(X)\n    Y = np.array(Y)\n    if len(X.shape) == 1:\n        X.shape = X.shape + (1,)\n    assert X.shape[0] == Y.shape[0], \"X and Y must have the same number of items\"\n    if len(Y.shape) &gt; 1:\n        Y = Y.ravel()\n        assert X.shape[0] == Y.shape[0], \"Y cannot have multiple columns!\"\n    self._logit = logit\n    self._normalise = normalise\n    self._X = X\n    self._Y = Y\n    self._x = None\n    self._y = None\n    self._weight = None\n    self._alpha = None\n    self._coefficients = None\n    # Preprocess data\n    if logit:\n        Y = limited_logit(Y)\n    if normalise:\n        X2, x_cols = remove_constant_columns(X)\n        if X.shape[1] == X2.shape[1]:\n            x_cols = None\n        X, x_center, x_scale = normalise_robust(X2)\n        if logit:\n            (y_center, y_scale) = (0, 1)\n        else:\n            Y, y_center, y_scale = normalise_robust(Y)\n        self._scale = DataScaling(x_center, x_scale, y_center, y_scale, x_cols)\n    else:\n        self._scale = None\n    self._X2 = X\n    self._Y2 = Y\n    self.num_threads = num_threads\n    check_threading_layer()\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.explain","title":"<code>explain(x, y=None, weight=None, init=None)</code>","text":"<p>Explain an outcome from a black box model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, int]</code> <p>Data item to explain, or an index to get the item from self.X</p> required <code>y</code> <code>Union[float, None]</code> <p>Prediction to explain. If x is an index then this should be None (y is taken from self.Y). Defaults to None.</p> <code>None</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>init</code> <code>Union[None, ndarray, Tuple[ndarray, float]]</code> <p>Use this alpha (and beta) value instead of the initialisation function. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>SliseExplainer</code> <code>SliseExplainer</code> <p><code>self</code> (containing the explanation).</p> Source code in <code>slise/slise.py</code> <pre><code>def explain(\n    self,\n    x: Union[np.ndarray, int],\n    y: Union[float, None] = None,\n    weight: Optional[np.ndarray] = None,\n    init: Union[None, np.ndarray, Tuple[np.ndarray, float]] = None,\n) -&gt; SliseExplainer:\n    \"\"\"Explain an outcome from a black box model\n\n    Args:\n        x (Union[np.ndarray, int]): Data item to explain, or an index to get the item from self.X\n        y (Union[float, None], optional): Prediction to explain. If x is an index then this should be None (y is taken from self.Y). Defaults to None.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        init (Union[None, np.ndarray, Tuple[np.ndarray, float]], optional): Use this alpha (and beta) value instead of the initialisation function. Defaults to None.\n\n    Returns:\n        SliseExplainer: `self` (containing the explanation).\n    \"\"\"\n    if weight is None:\n        self._weight = None\n    else:\n        self._weight = np.array(weight)\n        assert len(self._weight) == len(\n            self._Y\n        ), \"Y and weight must have the same number of items!\"\n        assert np.all(self._weight &gt;= 0.0), \"Weights must not be negative!\"\n    if y is None:\n        assert isinstance(x, int) and (\n            0 &lt;= x &lt; self._Y.shape[0]\n        ), \"If y is None then x must be an integer index [0, len(Y)[\"\n        self._y = self._Y[x]\n        self._x = self._X[x, :]\n        y = self._Y2[x]\n        x = self._X2[x, :]\n    else:\n        x = np.atleast_1d(np.array(x))\n        self._x = x\n        self._y = y\n        if self._logit:\n            y = limited_logit(y)\n        if self._normalise:\n            x = self._scale.scale_x(x)\n            y = self._scale.scale_y(y)\n    X = self._X2 - x[None, :]\n    Y = self._Y2 - y\n    threads = set_threads(self.num_threads)\n    try:\n        if init is None:\n            alpha, beta = self.init_fn(X, Y, self.epsilon, self._weight)\n        else:\n            alpha, beta = initialise_fixed(init, X, Y, self.epsilon, self._weight)\n        alpha = graduated_optimisation(\n            alpha=alpha,\n            X=X,\n            Y=Y,\n            epsilon=self.epsilon,\n            beta=beta,\n            lambda1=self.lambda1,\n            lambda2=self.lambda2,\n            weight=self._weight,\n            beta_max=self.beta_max,\n            max_approx=self.max_approx,\n            max_iterations=self.max_iterations,\n            debug=self.debug,\n        )\n    finally:\n        set_threads(threads)\n    alpha = np.concatenate(\n        (y - np.sum(alpha * x, dtype=x.dtype, keepdims=True), alpha)\n    )\n    self._alpha = alpha\n    if self._normalise:\n        y = self._y\n        if self._logit:\n            y = limited_logit(y)\n        alpha2 = self._scale.unscale_model(alpha)\n        alpha2[0] = y - np.sum(self._x * alpha2[1:])\n        self._coefficients = alpha2\n    else:\n        self._coefficients = alpha\n    return self\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.get_params","title":"<code>get_params(normalised=False)</code>","text":"<p>Get the explanation as the coefficients of a linear model (approximating the black box model).</p> <p>Parameters:</p> Name Type Description Default <code>normalised</code> <code>bool</code> <p>If the data is normalised within SLISE, return a linear model fitting the normalised data. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).</p> Source code in <code>slise/slise.py</code> <pre><code>def get_params(self, normalised: bool = False) -&gt; np.ndarray:\n    \"\"\"Get the explanation as the coefficients of a linear model (approximating the black box model).\n\n    Args:\n        normalised (bool, optional): If the data is normalised within SLISE, return a linear model fitting the normalised data. Defaults to False.\n\n    Returns:\n        np.ndarray: The coefficients of the linear model (the first scalar in the vector is the intercept).\n    \"\"\"\n    warn(\"Use `coefficients` instead of `get_params().\", SliseWarning)\n    return self._alpha if normalised else self._coefficients\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.normalised","title":"<code>normalised(all_columns=True)</code>","text":"<p>Get coefficients for normalised data (if the data is normalised within SLISE).</p> <p>Parameters:</p> Name Type Description Default <code>all_columns</code> <code>bool</code> <p>Add coefficients for constant columns. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Optional[np.ndarray]: The normalised coefficients or None.</p> Source code in <code>slise/slise.py</code> <pre><code>def normalised(self, all_columns: bool = True) -&gt; Optional[np.ndarray]:\n    \"\"\"Get coefficients for normalised data (if the data is normalised within SLISE).\n\n    Args:\n        all_columns (bool, optional): Add coefficients for constant columns. Defaults to True.\n\n    Returns:\n        Optional[np.ndarray]: The normalised coefficients or None.\n    \"\"\"\n    if self._alpha is None:\n        warn(\"Fit an explanation before retrieving coefficients\", SliseWarning)\n    if self._normalise:\n        if all_columns:\n            return add_constant_columns(self._alpha, self._scale.columns, True)\n        else:\n            return self._alpha\n    else:\n        return None\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.predict","title":"<code>predict(X=None)</code>","text":"<p>Use the approximating linear model to predict new outcomes.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[ndarray, None]</code> <p>Sata matrix to predict, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Prediction vector.</p> Source code in <code>slise/slise.py</code> <pre><code>def predict(self, X: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n    \"\"\"Use the approximating linear model to predict new outcomes.\n\n    Args:\n        X (Union[np.ndarray, None], optional): Sata matrix to predict, or None for using the fitted dataset. Defaults to None.\n\n    Returns:\n        np.ndarray: Prediction vector.\n    \"\"\"\n    if X is None:\n        Y = mat_mul_inter(self._X, self.coefficients)\n    else:\n        Y = mat_mul_inter(X, self.coefficients)\n    if self._logit:\n        Y = sigmoid(Y)\n    return Y\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.score","title":"<code>score(X=None, Y=None)</code>","text":"<p>Calculate the loss. Lower is better and it should usually be negative (unless the regularisation is very (/too?) strong).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[ndarray, None]</code> <p>Data matrix, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <code>Y</code> <code>Union[ndarray, None]</code> <p>Response vector, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The loss.</p> Source code in <code>slise/slise.py</code> <pre><code>def score(\n    self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n) -&gt; float:\n    \"\"\"Calculate the loss. Lower is better and it should usually be negative (unless the regularisation is very (/too?) strong).\n\n    Args:\n        X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n        Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n    Returns:\n        float: The loss.\n    \"\"\"\n    if self._alpha is None:\n        warn(\"Fit an explanation before calculating the score\", SliseWarning)\n    x = self._x\n    y = self._y\n    if self._logit:\n        y = limited_logit(y)\n    if self._normalise:\n        x = self._scale.scale_x(x)\n        y = self._scale.scale_y(y)\n    if X is None or Y is None:\n        X = self._X2\n        Y = self._Y2\n    else:\n        if self._logit:\n            Y = limited_logit(Y)\n        if self._normalise:\n            X = self._scale.scale_x(X)\n            Y = self._scale.scale_y(Y)\n    X = X - x[None, :]\n    Y = Y - y\n    return loss_sharp(\n        self._alpha[1:],\n        X,\n        Y,\n        self.epsilon,\n        self.lambda1,\n        self.lambda2,\n        self._weight,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.subset","title":"<code>subset(X=None, Y=None)</code>","text":"<p>Get the subset / neighbourhood used for the approximation (explanation).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[ndarray, None]</code> <p>Data matrix, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <code>Y</code> <code>Union[ndarray, None]</code> <p>Response vector, or None for using the fitted dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The subset as a boolean mask.</p> Source code in <code>slise/slise.py</code> <pre><code>def subset(\n    self, X: Union[np.ndarray, None] = None, Y: Union[np.ndarray, None] = None\n) -&gt; np.ndarray:\n    \"\"\"Get the subset / neighbourhood used for the approximation (explanation).\n\n    Args:\n        X (Union[np.ndarray, None], optional): Data matrix, or None for using the fitted dataset. Defaults to None.\n        Y (Union[np.ndarray, None], optional): Response vector, or None for using the fitted dataset. Defaults to None.\n\n    Returns:\n        np.ndarray: The subset as a boolean mask.\n    \"\"\"\n    if X is None or Y is None:\n        X = self._X\n        Y = self._Y\n    if self._logit:\n        Y = limited_logit(Y)\n    res = mat_mul_inter(X, self.coefficients) - Y\n    return res**2 &lt; self.scaled_epsilon**2\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.get_terms","title":"<code>get_terms(normalised=False, x=None)</code>","text":"<p>Get the \"terms\" of different variables on the outcome.     The terms are the (normalised) coefficients times the (normalised) values.</p> <p>Parameters:</p> Name Type Description Default <code>normalised</code> <code>bool</code> <p>Return the normalised terms (if normalisation is used). Defaults to False.</p> <code>False</code> <code>x</code> <code>Union[None, ndarray]</code> <p>The item to calculate the terms for (uses the explained item if None). Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The terms vector.</p> Source code in <code>slise/slise.py</code> <pre><code>def get_terms(\n    self, normalised: bool = False, x: Union[None, np.ndarray] = None\n) -&gt; np.ndarray:\n    \"\"\"Get the \"terms\" of different variables on the outcome.\n        The terms are the (normalised) coefficients times the (normalised) values.\n\n    Args:\n        normalised (bool, optional): Return the normalised terms (if normalisation is used). Defaults to False.\n        x (Union[None, np.ndarray], optional): The item to calculate the terms for (uses the explained item if None). Defaults to None.\n\n    Returns:\n        np.ndarray: The terms vector.\n    \"\"\"\n    if x is None:\n        x = self._x\n    if normalised and self._normalise:\n        x = add_constant_columns(self._scale.scale_x(x), self._scale.columns, False)\n        return add_intercept_column(x) * self.coefficients\n    else:\n        return add_intercept_column(x) * self.coefficients\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.print","title":"<code>print(variables=None, classes=None, num_var=10, decimals=3)</code>","text":"<p>Print the current explanation.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>Union[List[str], None]</code> <p>Names of the (columns/) variables. Defaults to None.</p> <code>None</code> <code>classes</code> <code>Union[List[str], None]</code> <p>Names of the classes, if explaining a classifier. Defaults to None.</p> <code>None</code> <code>num_var</code> <code>int</code> <p>Exclude zero weights if there are too many variables. Defaults to 10.</p> <code>10</code> <code>decimals</code> <code>int</code> <p>Precision to use for printing. Defaults to 3.</p> <code>3</code> Source code in <code>slise/slise.py</code> <pre><code>def print(\n    self,\n    variables: Union[List[str], None] = None,\n    classes: Union[List[str], None] = None,\n    num_var: int = 10,\n    decimals: int = 3,\n):\n    \"\"\"Print the current explanation.\n\n    Args:\n        variables (Union[List[str], None], optional): Names of the (columns/) variables. Defaults to None.\n        classes (Union[List[str], None], optional): Names of the classes, if explaining a classifier. Defaults to None.\n        num_var (int, optional): Exclude zero weights if there are too many variables. Defaults to 10.\n        decimals (int, optional): Precision to use for printing. Defaults to 3.\n    \"\"\"\n    print_slise(\n        self.coefficients,\n        True,\n        self.subset(),\n        self.score(),\n        self.scaled_epsilon,\n        variables,\n        \"SLISE Explanation\",\n        decimals,\n        num_var,\n        unscaled=self._x,\n        unscaled_y=self._y,\n        terms=self.get_terms(False),\n        scaled=None if self._scale is None else self._scale.scale_x(self._x, False),\n        alpha=self.normalised(),\n        scaled_terms=None if self._scale is None else self.get_terms(True),\n        classes=classes,\n        unscaled_preds=self._Y,\n        logit=self._logit,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.plot_2d","title":"<code>plot_2d(title='SLISE Explanation', label_x='x', label_y='y', decimals=3, fig=None)</code>","text":"<p>Plot the explanation in a 2D scatter plot (where the explained item is marked) with a line for the approximating model.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Explanation\".</p> <code>'SLISE Explanation'</code> <code>label_x</code> <code>str</code> <p>x-axis label. Defaults to \"x\".</p> <code>'x'</code> <code>label_y</code> <code>str</code> <p>Y-axis label. Defaults to \"y\".</p> <code>'y'</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing numbers. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>SliseException</code> <p>If the data has too many dimensions.</p> Source code in <code>slise/slise.py</code> <pre><code>def plot_2d(\n    self,\n    title: str = \"SLISE Explanation\",\n    label_x: str = \"x\",\n    label_y: str = \"y\",\n    decimals: int = 3,\n    fig: Union[Figure, None] = None,\n) -&gt; SliseRegression:\n    \"\"\"Plot the explanation in a 2D scatter plot (where the explained item is marked) with a line for the approximating model.\n\n    Args:\n        title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n        label_x (str, optional): x-axis label. Defaults to \"x\".\n        label_y (str, optional): Y-axis label. Defaults to \"y\".\n        decimals (int, optional): Number of decimals when writing numbers. Defaults to 3.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n\n    Raises:\n        SliseException: If the data has too many dimensions.\n    \"\"\"\n    plot_2d(\n        self._X,\n        self._Y,\n        self.coefficients,\n        self.scaled_epsilon,\n        self._x,\n        self._y,\n        self._logit,\n        title,\n        label_x,\n        label_y,\n        decimals,\n        fig,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.plot_image","title":"<code>plot_image(width, height, saturated=True, title='SLISE Explanation', classes=None, decimals=3, fig=None)</code>","text":"<p>Plot the current explanation for a black and white image (e.g. MNIST).</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>Width of the image.</p> required <code>height</code> <code>int</code> <p>Height of the image.</p> required <code>saturated</code> <code>bool</code> <p>Should the explanation be more saturated. Defaults to True.</p> <code>True</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Explanation\".</p> <code>'SLISE Explanation'</code> <code>classes</code> <code>Union[List, str, None]</code> <p>List of class names (first the negative, then the positive), or a single (positive) class name. Defaults to None.</p> <code>None</code> <code>decimals</code> <code>int</code> <p>Number of decimals to write. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/slise.py</code> <pre><code>def plot_image(\n    self,\n    width: int,\n    height: int,\n    saturated: bool = True,\n    title: str = \"SLISE Explanation\",\n    classes: Union[List, str, None] = None,\n    decimals: int = 3,\n    fig: Union[Figure, None] = None,\n) -&gt; SliseExplainer:\n    \"\"\"Plot the current explanation for a black and white image (e.g. MNIST).\n\n    Args:\n        width (int): Width of the image.\n        height (int): Height of the image.\n        saturated (bool, optional): Should the explanation be more saturated. Defaults to True.\n        title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n        classes (Union[List, str, None], optional): List of class names (first the negative, then the positive), or a single (positive) class name. Defaults to None.\n        decimals (int, optional): Number of decimals to write. Defaults to 3.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    plot_image(\n        self._x,\n        self._y,\n        self._Y,\n        self.coefficients,\n        width,\n        height,\n        saturated,\n        title,\n        classes,\n        decimals,\n        fig,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.plot_dist","title":"<code>plot_dist(title='SLISE Explanation', variables=None, order=None, decimals=3, fig=None)</code>","text":"<p>Plot the current explanation with density distributions for the dataset and a barplot for the model.</p> <p>The barplot contains both the approximating linear model (where the weights can be loosely interpreted as the importance of the different variables and their sign) and the \"terms\", which is the (scaled) model time the (scaled) item values. The terms demonstrates how the explained item interacts with the approximating linear model, since a negative weight times a negative value actually supports a positive prediction.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"SLISE Explanation\".</p> <code>'SLISE Explanation'</code> <code>variables</code> <code>list</code> <p>Names for the variables. Defaults to None.</p> <code>None</code> <code>order</code> <code>Union[None, int, Sequence[int]]</code> <p>Select variables (None: all, int: largest, selected). Defaults to all.</p> <code>None</code> <code>decimals</code> <code>int</code> <p>Number of decimals to write. Defaults to 3.</p> <code>3</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/slise.py</code> <pre><code>def plot_dist(\n    self,\n    title: str = \"SLISE Explanation\",\n    variables: list = None,\n    order: Union[None, int, Sequence[int]] = None,\n    decimals: int = 3,\n    fig: Union[Figure, None] = None,\n) -&gt; SliseExplainer:\n    \"\"\"Plot the current explanation with density distributions for the dataset and a barplot for the model.\n\n    The barplot contains both the approximating linear model (where the weights can be loosely interpreted as the importance of the different variables and their sign) and the \"terms\", which is the (scaled) model time the (scaled) item values.\n    The terms demonstrates how the explained item interacts with the approximating linear model, since a negative weight times a negative value actually supports a positive prediction.\n\n    Args:\n        title (str, optional): Title of the plot. Defaults to \"SLISE Explanation\".\n        variables (list, optional): Names for the variables. Defaults to None.\n        order (Union[None, int, Sequence[int]], optional): Select variables (None: all, int: largest, selected). Defaults to all.\n        decimals (int, optional): Number of decimals to write. Defaults to 3.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    plot_dist(\n        X=self._X,\n        Y=self._Y,\n        model=self.coefficients,\n        subset=self.subset(),\n        alpha=self.normalised(),\n        x=self._x,\n        y=self._y,\n        terms=self.get_terms(False),\n        norm_terms=self.get_terms(True) if self._normalise else None,\n        title=title,\n        variables=variables,\n        order=order,\n        decimals=decimals,\n        fig=fig,\n    )\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.SliseExplainer.plot_subset","title":"<code>plot_subset(title='Prediction Distribution', decimals=0, fig=None)</code>","text":"<p>Plot a density distributions for predictions and the predictions of the subset</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \"Prediction Distribution\".</p> <code>'Prediction Distribution'</code> <code>decimals</code> <code>int</code> <p>Number of decimals when writing the subset size. Defaults to 0.</p> <code>0</code> <code>fig</code> <code>Union[Figure, None]</code> <p>Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.</p> <code>None</code> Source code in <code>slise/slise.py</code> <pre><code>def plot_subset(\n    self,\n    title: str = \"Prediction Distribution\",\n    decimals: int = 0,\n    fig: Union[Figure, None] = None,\n):\n    \"\"\"Plot a density distributions for predictions and the predictions of the subset\n\n    Args:\n        title (str, optional): Title of the plot. Defaults to \"Prediction Distribution\".\n        decimals (int, optional): Number of decimals when writing the subset size. Defaults to 0.\n        fig (Union[Figure, None], optional): Pyplot figure to plot on, if None then a new plot is created and shown. Defaults to None.\n    \"\"\"\n    plot_dist_single(self._Y, self.subset(), self._y, title, decimals, fig)\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.regression","title":"<code>regression(X, Y, epsilon, lambda1=0, lambda2=0, weight=None, intercept=True, normalise=False, init=None, initialisation=initialise_candidates, beta_max=20, max_approx=1.15, max_iterations=300, debug=False, num_threads=1)</code>","text":"<p>Use SLISE for robust regression</p> <p>In robust regression we fit regression models that can handle data that contains outliers. SLISE accomplishes this by fitting a model such that the largest possible subset of the data items have an error less than a given value. All items with an error larger than that are considered potential outliers and do not affect the resulting model.</p> <p>It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE. This is a wrapper around slise.slise.SliseRegression that is equivalent to <code>SliseRegression(epsilon, **kwargs).fit(X, Y)</code></p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Response vector.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>lambda1</code> <code>float</code> <p>L1 regularisation strength. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>L2 regularisation strength. Defaults to 0.</p> <code>0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>intercept</code> <code>bool</code> <p>Add an intercept term. Defaults to True.</p> <code>True</code> <code>normalise</code> <code>bool</code> <p>Should X aclasses not be scaled). Defaults to False.</p> <code>False</code> <code>init</code> <code>Union[None, ndarray, Tuple[ndarray, float]]</code> <p>Use this alpha (and beta) value instead of the initialisation function. Defaults to None.</p> <code>None</code> <code>initialisation</code> <code>Callable[[ndarray, ndarray, float, Optional[ndarray]], Tuple[ndarray, float]]</code> <p>Function that takes <code>(X, Y, epsilon, weight)</code> and gives an initial values for alpha and beta. Defaults to initialise_candidates.</p> <code>initialise_candidates</code> <code>beta_max</code> <code>float</code> <p>The stopping sigmoid steepness. Defaults to 20.</p> <code>20</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of OWL-QN iterations. Defaults to 300.</p> <code>300</code> <code>debug</code> <code>bool</code> <p>Print debug statements each graduated optimisation step. Defaults to False.</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>SliseRegression</code> <code>SliseRegression</code> <p>Object containing the regression result.</p> Source code in <code>slise/slise.py</code> <pre><code>def regression(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    weight: Optional[np.ndarray] = None,\n    intercept: bool = True,\n    normalise: bool = False,\n    init: Union[None, np.ndarray, Tuple[np.ndarray, float]] = None,\n    initialisation: Callable[\n        [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float]\n    ] = initialise_candidates,\n    beta_max: float = 20,\n    max_approx: float = 1.15,\n    max_iterations: int = 300,\n    debug: bool = False,\n    num_threads: int = 1,\n) -&gt; SliseRegression:\n    \"\"\"Use SLISE for robust regression\n\n    In robust regression we fit regression models that can handle data that\n    contains outliers. SLISE accomplishes this by fitting a model such that\n    the largest possible subset of the data items have an error less than a\n    given value. All items with an error larger than that are considered\n    potential outliers and do not affect the resulting model.\n\n    It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.\n    This is a wrapper around [slise.slise.SliseRegression][] that is equivalent to `SliseRegression(epsilon, **kwargs).fit(X, Y)`\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Response vector.\n        epsilon (float): Error tolerance.\n        lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n        lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        intercept (bool, optional): Add an intercept term. Defaults to True.\n        normalise (bool, optional): Should X aclasses not be scaled). Defaults to False.\n        init (Union[None, np.ndarray, Tuple[np.ndarray, float]], optional): Use this alpha (and beta) value instead of the initialisation function. Defaults to None.\n        initialisation (Callable[ [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float] ], optional): Function that takes `(X, Y, epsilon, weight)` and gives an initial values for alpha and beta. Defaults to initialise_candidates.\n        beta_max (float, optional): The stopping sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        max_iterations (int, optional): Maximum number of OWL-QN iterations. Defaults to 300.\n        debug (bool, optional): Print debug statements each graduated optimisation step. Defaults to False.\n        num_threads (int, optional): The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.\n\n    Returns:\n        SliseRegression: Object containing the regression result.\n    \"\"\"\n    return SliseRegression(\n        epsilon=epsilon,\n        lambda1=lambda1,\n        lambda2=lambda2,\n        intercept=intercept,\n        normalise=normalise,\n        initialisation=initialisation,\n        beta_max=beta_max,\n        max_approx=max_approx,\n        max_iterations=max_iterations,\n        debug=debug,\n        num_threads=num_threads,\n    ).fit(X=X, Y=Y, weight=weight, init=init)\n</code></pre>"},{"location":"docs/slise.slise/#slise.slise.explain","title":"<code>explain(X, Y, epsilon, x, y=None, lambda1=0, lambda2=0, weight=None, normalise=False, logit=False, init=None, initialisation=initialise_candidates, beta_max=20, max_approx=1.15, max_iterations=300, debug=False, num_threads=1)</code>","text":"<p>Use SLISE for explaining outcomes from black box models.</p> <p>SLISE can also be used to provide local model-agnostic explanations for outcomes from black box models. To do this we replace the ground truth response vector with the predictions from the complex model. Furthermore, we force the model to fit a selected item (making the explanation local). This gives us a local approximation of the complex model with a simpler linear model. In contrast to other methods SLISE creates explanations using real data (not some discretised and randomly sampled data) so we can be sure that all inputs are valid (i.e. in the correct data manifold, and follows the constraints used to generate the data, e.g., the laws of physics).</p> <p>It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE. This is a wrapper around slise.slise.SliseExplainer that is equivalent to <code>SliseExplainer(X, Y, epsilon, **kwargs).explain(x, y)</code></p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Data matrix.</p> required <code>Y</code> <code>ndarray</code> <p>Vector of predictions.</p> required <code>epsilon</code> <code>float</code> <p>Error tolerance.</p> required <code>x</code> <code>Union[ndarray, int]</code> <p>The data item to explain, or an index to get the item from self.X</p> required <code>y</code> <code>Union[float, None]</code> <p>The outcome to explain. If x is an index then this should be None (y is taken from self.Y). Defaults to None.</p> <code>None</code> <code>lambda1</code> <code>float</code> <p>L1 regularisation strength. Defaults to 0.</p> <code>0</code> <code>lambda2</code> <code>float</code> <p>L2 regularisation strength. Defaults to 0.</p> <code>0</code> <code>weight</code> <code>Optional[ndarray]</code> <p>Weight vector for the data items. Defaults to None.</p> <code>None</code> <code>normalise</code> <code>bool</code> <p>Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.</p> <code>False</code> <code>logit</code> <code>bool</code> <p>Do a logit transformation on the Y vector, this is recommended only if Y consists of probabilities. Defaults to False.</p> <code>False</code> <code>init</code> <code>Union[None, ndarray, Tuple[ndarray, float]]</code> <p>Use this alpha (and beta) value instead of the initialisation function. Defaults to None.</p> <code>None</code> <code>initialisation</code> <code>Callable[[ndarray, ndarray, float, Optional[ndarray]], Tuple[ndarray, float]]</code> <p>Function that takes <code>(X, Y, epsilon, weight)</code> and gives an initial values for alpha and beta. Defaults to initialise_candidates.</p> <code>initialise_candidates</code> <code>beta_max</code> <code>float</code> <p>The final sigmoid steepness. Defaults to 20.</p> <code>20</code> <code>max_approx</code> <code>float</code> <p>Approximation ratio when selecting the next beta. Defaults to 1.15.</p> <code>1.15</code> <code>max_iterations</code> <code>int</code> <p>Maximum number of OWL-QN iterations. Defaults to 300.</p> <code>300</code> <code>debug</code> <code>bool</code> <p>Print debug statements each graduated optimisation step. Defaults to False.</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>SliseExplainer</code> <code>SliseExplainer</code> <p>Object containing the explanation.</p> Source code in <code>slise/slise.py</code> <pre><code>def explain(\n    X: np.ndarray,\n    Y: np.ndarray,\n    epsilon: float,\n    x: Union[np.ndarray, int],\n    y: Union[float, None] = None,\n    lambda1: float = 0,\n    lambda2: float = 0,\n    weight: Optional[np.ndarray] = None,\n    normalise: bool = False,\n    logit: bool = False,\n    init: Union[None, np.ndarray, Tuple[np.ndarray, float]] = None,\n    initialisation: Callable[\n        [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float]\n    ] = initialise_candidates,\n    beta_max: float = 20,\n    max_approx: float = 1.15,\n    max_iterations: int = 300,\n    debug: bool = False,\n    num_threads: int = 1,\n) -&gt; SliseExplainer:\n    \"\"\"Use SLISE for explaining outcomes from black box models.\n\n    SLISE can also be used to provide local model-agnostic explanations for\n    outcomes from black box models. To do this we replace the ground truth\n    response vector with the predictions from the complex model. Furthermore, we\n    force the model to fit a selected item (making the explanation local). This\n    gives us a local approximation of the complex model with a simpler linear\n    model. In contrast to other methods SLISE creates explanations using real\n    data (not some discretised and randomly sampled data) so we can be sure that\n    all inputs are valid (i.e. in the correct data manifold, and follows the\n    constraints used to generate the data, e.g., the laws of physics).\n\n    It is highly recommended that you normalise the data, either before using SLISE or by setting normalise = TRUE.\n    This is a wrapper around [slise.slise.SliseExplainer][] that is equivalent to `SliseExplainer(X, Y, epsilon, **kwargs).explain(x, y)`\n\n    Args:\n        X (np.ndarray): Data matrix.\n        Y (np.ndarray): Vector of predictions.\n        epsilon (float): Error tolerance.\n        x (Union[np.ndarray, int]): The data item to explain, or an index to get the item from self.X\n        y (Union[float, None], optional): The outcome to explain. If x is an index then this should be None (y is taken from self.Y). Defaults to None.\n        lambda1 (float, optional): L1 regularisation strength. Defaults to 0.\n        lambda2 (float, optional): L2 regularisation strength. Defaults to 0.\n        weight (Optional[np.ndarray], optional): Weight vector for the data items. Defaults to None.\n        normalise (bool, optional): Should X and Y be normalised (note that epsilon will not be scaled). Defaults to False.\n        logit (bool, optional): Do a logit transformation on the Y vector, this is recommended only if Y consists of probabilities. Defaults to False.\n        init (Union[None, np.ndarray, Tuple[np.ndarray, float]], optional): Use this alpha (and beta) value instead of the initialisation function. Defaults to None.\n        initialisation (Callable[ [np.ndarray, np.ndarray, float, Optional[np.ndarray]], Tuple[np.ndarray, float] ], optional): Function that takes `(X, Y, epsilon, weight)` and gives an initial values for alpha and beta. Defaults to initialise_candidates.\n        beta_max (float, optional): The final sigmoid steepness. Defaults to 20.\n        max_approx (float, optional): Approximation ratio when selecting the next beta. Defaults to 1.15.\n        max_iterations (int, optional): Maximum number of OWL-QN iterations. Defaults to 300.\n        debug (bool, optional): Print debug statements each graduated optimisation step. Defaults to False.\n        num_threads (int, optional): The number of numba threads. Set to -1 to use numba defaults. Values &gt;1 sometimes cause unexpectedly large overhead on some CPUs. Defaults to 1.\n\n    Returns:\n        SliseExplainer: Object containing the explanation.\n    \"\"\"\n    return SliseExplainer(\n        X=X,\n        Y=Y,\n        epsilon=epsilon,\n        lambda1=lambda1,\n        lambda2=lambda2,\n        normalise=normalise,\n        logit=logit,\n        initialisation=initialisation,\n        beta_max=beta_max,\n        max_approx=max_approx,\n        max_iterations=max_iterations,\n        debug=debug,\n        num_threads=num_threads,\n    ).explain(x=x, y=y, weight=weight, init=init)\n</code></pre>"},{"location":"docs/slise.utils/","title":"slise.utils","text":""},{"location":"docs/slise.utils/#slise.utils","title":"<code>slise.utils</code>","text":"<p>This script contains some utility functions.</p>"},{"location":"docs/slise.utils/#slise.utils.SliseWarning","title":"<code>SliseWarning</code>","text":"<p>             Bases: <code>RuntimeWarning</code></p> <p>Custom tag for warnings.</p> Source code in <code>slise/utils.py</code> <pre><code>class SliseWarning(RuntimeWarning):\n    \"\"\"\n    Custom tag for warnings.\n    \"\"\"\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.SliseException","title":"<code>SliseException</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Custom tag for exceptions.</p> Source code in <code>slise/utils.py</code> <pre><code>class SliseException(Exception):\n    \"\"\"\n    Custom tag for exceptions.\n    \"\"\"\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.limited_logit","title":"<code>limited_logit(p, stab=0.001)</code>","text":"<p>Computes logits from probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Union[ndarray, float]</code> <p>Probability vector or scalar.</p> required <code>stab</code> <code>float</code> <p>Limit p to [stab, 1-stab] for numerical stability. Defaults to 0.001.</p> <code>0.001</code> <p>Returns:</p> Type Description <code>Union[ndarray, float]</code> <p>Union[np.ndarray, float]: <code>logit(clamp(p, stab, 1-stab))</code>.</p> Source code in <code>slise/utils.py</code> <pre><code>def limited_logit(\n    p: Union[np.ndarray, float], stab: float = 0.001\n) -&gt; Union[np.ndarray, float]:\n    \"\"\"Computes logits from probabilities.\n\n    Args:\n        p (Union[np.ndarray, float]): Probability vector or scalar.\n        stab (float, optional): Limit p to [stab, 1-stab] for numerical stability. Defaults to 0.001.\n\n    Returns:\n        Union[np.ndarray, float]: `logit(clamp(p, stab, 1-stab))`.\n    \"\"\"\n    p = np.minimum(1.0 - stab, np.maximum(stab, p))\n    return np.log(p / (1.0 - p))\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.dsigmoid","title":"<code>dsigmoid(x)</code>","text":"<p>Derivative of the sigmoid function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, float]</code> <p>Real vector or scalar.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, float]</code> <p>Union[np.ndarray, float]: Derivative of <code>sigmoid(x)</code>.</p> Source code in <code>slise/utils.py</code> <pre><code>def dsigmoid(x: Union[np.ndarray, float]) -&gt; Union[np.ndarray, float]:\n    \"\"\"Derivative of the sigmoid function.\n\n    Args:\n        x (Union[np.ndarray, float]): Real vector or scalar.\n\n    Returns:\n        Union[np.ndarray, float]: Derivative of `sigmoid(x)`.\n    \"\"\"\n    s = sigmoid(x)\n    return s * (1 - s)\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.log_sigmoid","title":"<code>log_sigmoid(x)</code>","text":"<p>Computes <code>log(sigmoid(x))</code> in a numerically stable way.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, float]</code> <p>Real vector or scalar.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, float]</code> <p>Union[np.ndarray, float]: <code>log(sigmoid(x))</code></p> Source code in <code>slise/utils.py</code> <pre><code>def log_sigmoid(x: Union[np.ndarray, float]) -&gt; Union[np.ndarray, float]:\n    \"\"\"Computes `log(sigmoid(x))` in a numerically stable way.\n\n    Args:\n        x (Union[np.ndarray, float]): Real vector or scalar.\n\n    Returns:\n        Union[np.ndarray, float]: `log(sigmoid(x))`\n    \"\"\"\n    y = -np.sign(x)\n    return (y * 0.5 + 0.5) * x - np.log1p(np.exp(y * x))\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.dlog_sigmoid","title":"<code>dlog_sigmoid(x)</code>","text":"<p>Derivative of <code>log(sigmoid(x))</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, float]</code> <p>Real vector or scalar.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, float]</code> <p>Union[np.ndarray, float]: Derivative of <code>log(sigmoid(x))</code></p> Source code in <code>slise/utils.py</code> <pre><code>def dlog_sigmoid(x: Union[np.ndarray, float]) -&gt; Union[np.ndarray, float]:\n    \"\"\"Derivative of `log(sigmoid(x))`.\n\n    Args:\n        x (Union[np.ndarray, float]): Real vector or scalar.\n\n    Returns:\n        Union[np.ndarray, float]: Derivative of `log(sigmoid(x))`\n    \"\"\"\n    return 1 - sigmoid(x)\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.sparsity","title":"<code>sparsity(x, treshold=0)</code>","text":"<p>Count the number of <code>abs(x) &gt; treshold</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[ndarray, float]</code> <p>Real vector or scalar.</p> required <code>treshold</code> <code>float</code> <p>Threshold non-inclusive. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of <code>abs(x) &gt; treshold</code>.</p> Source code in <code>slise/utils.py</code> <pre><code>def sparsity(x: Union[np.ndarray, float], treshold: float = 0) -&gt; int:\n    \"\"\"Count the number of `abs(x) &gt; treshold`.\n\n    Args:\n        x (Union[np.ndarray, float]): Real vector or scalar.\n        treshold (float, optional): Threshold non-inclusive. Defaults to 0.\n\n    Returns:\n        int: The number of `abs(x) &gt; treshold`.\n    \"\"\"\n    if treshold &gt; 0:\n        return np.count_nonzero(np.abs(x) &gt; treshold)\n    else:\n        return np.count_nonzero(x)\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.log_sum_exp","title":"<code>log_sum_exp(x)</code>","text":"<p>Computes <code>log(sum(exp(x)))</code> in a numerically stable way.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Real vector.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p><code>log(sum(exp(x)))</code></p> Source code in <code>slise/utils.py</code> <pre><code>def log_sum_exp(x: np.ndarray) -&gt; float:\n    \"\"\"Computes `log(sum(exp(x)))` in a numerically stable way.\n\n    Args:\n        x (np.ndarray): Real vector.\n\n    Returns:\n        float: `log(sum(exp(x)))`\n    \"\"\"\n    xmax = np.max(x)\n    return xmax + np.log(np.sum(np.exp(x - xmax)))\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.log_sum_special","title":"<code>log_sum_special(x, y)</code>","text":"<p>Computes <code>log(sum(exp(x) * y))</code> (or <code>log(sum(exp(x)))</code> if <code>all(y == 0)</code>), in a numerically stable way.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Real vector.</p> required <code>y</code> <code>ndarray</code> <p>Real vector.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p><code>log(sum(exp(x) * y))</code>.</p> Source code in <code>slise/utils.py</code> <pre><code>def log_sum_special(x: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Computes `log(sum(exp(x) * y))` (or `log(sum(exp(x)))` if `all(y == 0)`), in a numerically stable way.\n\n    Args:\n        x (np.ndarray): Real vector.\n        y (np.ndarray): Real vector.\n\n    Returns:\n        float: `log(sum(exp(x) * y))`.\n    \"\"\"\n    xmax = np.max(x)\n    xexp = np.exp(x - xmax)\n    xsum = np.sum(xexp * y)\n    if xsum == 0:\n        xsum = np.sum(xexp)\n    return xmax + np.log(xsum)\n</code></pre>"},{"location":"docs/slise.utils/#slise.utils.mat_mul_inter","title":"<code>mat_mul_inter(X, alpha)</code>","text":"<p>Matrix multiplication, but check and handle potential intercepts in <code>alpha</code>.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Real matrix or vector.</p> required <code>alpha</code> <code>ndarray</code> <p>Real vector.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: <code>X @ alpha</code> or <code>X @ alpha[1:] + alpha[0]</code>.</p> Source code in <code>slise/utils.py</code> <pre><code>def mat_mul_inter(X: np.ndarray, alpha: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Matrix multiplication, but check and handle potential intercepts in `alpha`.\n\n    Args:\n        X (np.ndarray): Real matrix or vector.\n        alpha (np.ndarray): Real vector.\n\n    Returns:\n        np.ndarray: `X @ alpha` or `X @ alpha[1:] + alpha[0]`.\n    \"\"\"\n    alpha = np.atleast_1d(alpha)\n    if len(X.shape) == 1:\n        if len(alpha) == X.size:\n            return np.sum(alpha[1:] * X)\n        if len(alpha) == X.size + 1:\n            return alpha[0] + np.sum(alpha[1:] * X)\n        else:\n            X = np.reshape(X, X.shape + (1,))\n    if len(alpha) == X.shape[1] + 1:\n        return X @ alpha[1:] + alpha[0]\n    else:\n        return X @ alpha\n</code></pre>"}]}